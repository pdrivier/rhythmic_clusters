{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6890a69b",
   "metadata": {},
   "source": [
    "# clustering phase models\n",
    "\n",
    "Here, you specifically ask the question: *__how do different odors and visuospatial inputs recruit inhibitory interneurons__*, where recruitment corresponds to spike phase relationships with respect to four different rhythmic frequency bands. Note: because you are only considering correct trials, this will mean that a given odor also correlates perfectly with a given side of the maze in Lara's recording room in the Eichenbaum lab. For this reason, it may be the case that what is really driving differences in recruitment is the side of the maze that the rat finds itself in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "440a5274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset\n",
    "\n",
    "import itertools\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import seaborn as sns\n",
    "\n",
    "import kde_spikephase as kd\n",
    "\n",
    "from mdl_eval_tools import bayes, kl\n",
    "from rayleigh_pr import rayleigh_pr\n",
    "import re\n",
    "from scipy import stats\n",
    "from scipy.signal import hilbert, find_peaks\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "sns.set(font_scale=2,style='whitegrid') \n",
    "pd.set_option('max_colwidth',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8fd25e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neuron_cols(df,neuron_expression):\n",
    "    \"\"\"df: dataframe containing columns corresponding to neuron spiketimes\"\"\"\n",
    "    \n",
    "    pattern = re.compile(neuron_expression)\n",
    "    neuron_cols = []\n",
    "    for s in df.columns:\n",
    "\n",
    "        matched = pattern.match(s)\n",
    "        is_match = bool(matched)\n",
    "\n",
    "        if is_match:\n",
    "\n",
    "            neuron_cols.append(matched.string)\n",
    "    \n",
    "    return neuron_cols\n",
    "\n",
    "def get_allowable_lfp_wires(neuron_id,split_on):\n",
    "    \"\"\"neuron_id: string, e.g. TETSPK53b\n",
    "    split_on: string, e.g. 'K', you will use this to exclude the unit letter from neuron_id\"\"\"\n",
    "\n",
    "    #figure out who is the corresponding LFP for this neuron, must be on same tetrode!\n",
    "    unit_wirenum = neuron.split(split_on)[1]\n",
    "    unit_wirenum = unit_wirenum[:-1]\n",
    "    if len(unit_wirenum) > 2:\n",
    "        unit_wirenum = unit_wirenum[:2]\n",
    "    allow_wire = [int(unit_wirenum), int(unit_wirenum) + 1, int(unit_wirenum) + 2, int(unit_wirenum) + 3]\n",
    "    allow_wire = [str(w) for w in allow_wire]\n",
    "    allow_wire = ['0'+w if int(w)<10 else w for w in allow_wire]\n",
    "    \n",
    "    return allow_wire\n",
    "\n",
    "def get_lfp_cols(df,lfp_expression):\n",
    "    \"\"\"df: dataframe containing columns corresponding to neuron spiketimes\n",
    "    lfp_expression: string, e.g.\"\"\"\n",
    "#example lfp_expression =  \"TETFP\"+allow_wire[0]+\"\\Z|TETFP\"+allow_wire[1]+\"\\Z|TETFP\"+allow_wire[2]+\"\\Z|TETFP\"+allow_wire[3]+\"\\Z\"\n",
    "        \n",
    "    pattern = re.compile(lfp_expression)\n",
    "    lfp_cols = []\n",
    "    for s in df.columns:\n",
    "\n",
    "        matched = pattern.match(s)\n",
    "        is_match = bool(matched)\n",
    "\n",
    "        if is_match:\n",
    "\n",
    "            lfp_cols.append(matched.string)\n",
    "\n",
    "    return lfp_cols\n",
    "\n",
    "\n",
    "def example_cells_by_side_of_maze(cell_id,kde_odor,cluster_id_df,datapath,ymax,centered,savefig):\n",
    "    \n",
    "    example_cell_model = kde_odor[(kde_odor['cell_id'] == cell_id)]\n",
    "    example_cell_clust = cluster_id_df[cluster_id_df['cell_id']==cell_id]\n",
    "    \n",
    "    file = cell_id.split('_')[0] + '_' + cell_id.split('_')[1] + '_correct.csv'\n",
    "    example_cell_data = pd.read_csv(os.path.join(datapath,file))\n",
    "\n",
    "    neuron = cell_id.split('_')[2]\n",
    "    \n",
    "    #find out which positions each odor in example_cell_clust occurs in\n",
    "    condition_labels = list(set(example_cell_clust['condition_labels']))\n",
    "    odor_side = []\n",
    "    for condition in condition_labels: \n",
    "\n",
    "        which_pos = list(set(example_cell_data[example_cell_data['odor_labels']==condition]['pos_labels']))\n",
    "\n",
    "        if which_pos == [1,2]: \n",
    "\n",
    "            side = 'left'\n",
    "\n",
    "        elif which_pos == [3,4]: \n",
    "\n",
    "            side = 'right'\n",
    "\n",
    "        dct = {'condition_labels': condition,\n",
    "               'pos': which_pos,\n",
    "               'side_of_maze': side\n",
    "              }\n",
    "        odor_side.append(pd.DataFrame(dct))\n",
    "\n",
    "    odor_side_df = pd.concat(odor_side)\n",
    "    \n",
    "    example_cell_clust = example_cell_clust.merge(odor_side_df,on='condition_labels')\n",
    "    \n",
    "    rhythms = ['theta','beta','lowgamma','highgamma']\n",
    "\n",
    "    sides = list(set(odor_side_df['side_of_maze']))\n",
    "\n",
    "    fig,ax=plt.subplots(1,4,figsize=(20,5))\n",
    "\n",
    "    counter = 0\n",
    "    for side in sides: \n",
    "\n",
    "        if side == 'left':\n",
    "            side_color = 'rosybrown'\n",
    "\n",
    "\n",
    "        elif side == 'right': \n",
    "            side_color = 'steelblue'\n",
    "\n",
    "\n",
    "\n",
    "        subside = example_cell_clust[example_cell_clust['side_of_maze']==side]\n",
    "\n",
    "        conditions = list(set(subside['condition_labels']))\n",
    "\n",
    "        for condition in conditions: \n",
    "\n",
    "            for rhythm in rhythms:\n",
    "\n",
    "                subc = example_cell_model[(example_cell_model['condition_labels']==condition)&(example_cell_model['rhythm']==rhythm)]\n",
    "                clust_data = subside[subside['condition_labels']==condition]\n",
    "                inds = list(set(clust_data['spktrn_ind_labels']))\n",
    "\n",
    "                if centered:\n",
    "                    \n",
    "                    if rhythm == 'theta':\n",
    "\n",
    "                        varname = theta_kde_cent_odor\n",
    "\n",
    "                    elif rhythm == 'beta':\n",
    "\n",
    "                        varname = beta_kde_cent_odor\n",
    "\n",
    "                    elif rhythm == 'lowgamma': \n",
    "\n",
    "                        varname = lowgamma_kde_cent_odor\n",
    "\n",
    "                    elif rhythm == 'highgamma': \n",
    "\n",
    "                        varname = highgamma_kde_cent_odor\n",
    "                        \n",
    "                    if counter < 4:\n",
    "                        ax[counter].plot(x,varname[inds,:].T,color=side_color,linewidth=6,alpha=0.7);\n",
    "                        ax[counter].set_title(rhythm)\n",
    "                        ax[0].set_ylabel(cell_id)\n",
    "\n",
    "\n",
    "                        counter += 1\n",
    "\n",
    "                    if counter >= 4:\n",
    "\n",
    "                        counter = 0 #reset the counter\n",
    "                        \n",
    "                else:\n",
    "                    \n",
    "                    if counter < 4:\n",
    "                        ax[counter].plot(x,subc['kde_spikeprob'].values,color=side_color,linewidth=6,alpha=0.7);\n",
    "                        ax[counter].set_title(rhythm)\n",
    "                        ax[0].set_ylabel(cell_id)\n",
    "\n",
    "\n",
    "                        counter += 1\n",
    "\n",
    "                    if counter >= 4:\n",
    "\n",
    "                        counter = 0 #reset the counter\n",
    "           \n",
    "\n",
    "    if centered: \n",
    "        for a in ax:\n",
    "            a.set_ylim(-ymax,ymax)\n",
    "            \n",
    "    else: \n",
    "        for a in ax:\n",
    "            a.set_ylim(0,ymax)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    if savefig: \n",
    "        \n",
    "        fig.savefig('figures_odor/example_cell_'+cell_id+'_coloredby_odor_side_of_maze.pdf')\n",
    "\n",
    "\n",
    "\n",
    "    return \n",
    "\n",
    "\n",
    "\n",
    "def example_cells_by_odor(cell_id,kde_odor,cluster_id_df,ymax,centered):\n",
    "    \n",
    "    example_cell_model = kde_odor[(kde_odor['cell_id'] == cell_id)]\n",
    "    example_cell_clust = cluster_id_df[cluster_id_df['cell_id']==cell_id]\n",
    "\n",
    "    file = cell_id.split('_')[0] + '_' + cell_id.split('_')[1] + '_correct.csv'\n",
    "    example_cell_data = pd.read_csv(os.path.join(datapath,file))\n",
    "\n",
    "    neuron = cell_id.split('_')[2]\n",
    "\n",
    "    #find out which positions each odor in example_cell_clust occurs in\n",
    "    condition_labels = list(set(example_cell_clust['condition_labels']))\n",
    "    odor_side = []\n",
    "    for condition in condition_labels: \n",
    "\n",
    "        which_pos = list(set(example_cell_data[example_cell_data['odor_labels']==condition]['pos_labels']))\n",
    "\n",
    "        if which_pos == [1,2]: \n",
    "\n",
    "            side = 'left'\n",
    "\n",
    "        elif which_pos == [3,4]: \n",
    "\n",
    "            side = 'right'\n",
    "\n",
    "        dct = {'condition_labels': condition,\n",
    "               'pos': which_pos,\n",
    "               'side_of_maze': side\n",
    "              }\n",
    "        odor_side.append(pd.DataFrame(dct))\n",
    "\n",
    "    odor_side_df = pd.concat(odor_side)\n",
    "\n",
    "    example_cell_clust = example_cell_clust.merge(odor_side_df,on='condition_labels')\n",
    "\n",
    "    rhythms = ['theta','beta','lowgamma','highgamma']\n",
    "\n",
    "    sides = list(set(odor_side_df['side_of_maze']))\n",
    "\n",
    "    fig,ax=plt.subplots(1,4,figsize=(20,5))\n",
    "\n",
    "    counter = 0\n",
    "    for side in sides: \n",
    "\n",
    "        if side == 'left':\n",
    "            side_colors = ['red','rosybrown','firebrick','lightcoral']\n",
    "\n",
    "\n",
    "        elif side == 'right': \n",
    "            side_colors = ['steelblue','dodgerblue','lightskyblue','powderblue']\n",
    "\n",
    "\n",
    "        subside = example_cell_clust[example_cell_clust['side_of_maze']==side]\n",
    "\n",
    "        conditions = list(set(subside['condition_labels']))\n",
    "\n",
    "        for cind,condition in enumerate(conditions): \n",
    "\n",
    "            for rhythm in rhythms:\n",
    "\n",
    "                subc = example_cell_model[(example_cell_model['condition_labels']==condition)&(example_cell_model['rhythm']==rhythm)]\n",
    "                clust_data = subside[subside['condition_labels']==condition]\n",
    "                inds = list(set(clust_data['spktrn_ind_labels']))\n",
    "\n",
    "                if centered:\n",
    "\n",
    "                    if rhythm == 'theta':\n",
    "\n",
    "                        varname = theta_kde_cent_odor\n",
    "\n",
    "                    elif rhythm == 'beta':\n",
    "\n",
    "                        varname = beta_kde_cent_odor\n",
    "\n",
    "                    elif rhythm == 'lowgamma': \n",
    "\n",
    "                        varname = lowgamma_kde_cent_odor\n",
    "\n",
    "                    elif rhythm == 'highgamma': \n",
    "\n",
    "                        varname = highgamma_kde_cent_odor\n",
    "\n",
    "                    if counter < 4:\n",
    "\n",
    "                        if cind >= 4: \n",
    "\n",
    "                            cind = cind - 4\n",
    "\n",
    "                        ax[counter].plot(x,varname[inds,:].T,color=side_colors[cind],linewidth=6,alpha=0.7,label=str(condition));\n",
    "                        ax[counter].set_title(rhythm)\n",
    "                        ax[0].set_ylabel(cell_id)\n",
    "\n",
    "\n",
    "                        counter += 1\n",
    "\n",
    "                    if counter >= 4:\n",
    "\n",
    "                        counter = 0 #reset the counter\n",
    "\n",
    "\n",
    "                else:\n",
    "\n",
    "                    if counter < 4:\n",
    "\n",
    "                        if cind >= 4: \n",
    "\n",
    "                            cind = cind - 4\n",
    "\n",
    "                        ax[counter].plot(x,subc['kde_spikeprob'].values,color=side_colors[cind],linewidth=6,alpha=0.7,label=str(condition));\n",
    "                        ax[counter].set_title(rhythm)\n",
    "                        ax[0].set_ylabel(cell_id)\n",
    "\n",
    "\n",
    "                        counter += 1\n",
    "\n",
    "                    if counter >= 4:\n",
    "\n",
    "                        counter = 0 #reset the counter\n",
    "\n",
    "\n",
    "    if centered: \n",
    "        for a in ax:\n",
    "            a.set_ylim(-ymax,ymax)\n",
    "            \n",
    "\n",
    "    else: \n",
    "        for a in ax:\n",
    "            a.set_ylim(0,ymax)\n",
    "            \n",
    "    fig.legend()\n",
    "    fig.tight_layout()\n",
    "    \n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "\n",
    "def compute_circmean(phi_when_sp):\n",
    "    \n",
    "    #get cosine of all phase angles that coincide with spikes\n",
    "    tmpcos = [np.cos(i) for i in phi_when_sp]\n",
    "    #get sine of all phase angles that coincide with spikes\n",
    "    tmpsin = [np.sin(i) for i in phi_when_sp]\n",
    "\n",
    "    #take the average cosine component (x)\n",
    "    meancos = np.mean(tmpcos)\n",
    "    #take the average sine component (y)\n",
    "    meansin = np.mean(tmpsin)\n",
    "\n",
    "    #get the hypotenuse of the mean sin and cosine components\n",
    "    mrl = np.sqrt(meancos**2 + meansin**2)\n",
    "\n",
    "    #compute circular mean\n",
    "    circmean = np.arctan2(meansin,meancos)\n",
    "    \n",
    "    return circmean\n",
    "\n",
    "def label_phase_cycles(df, filtcol, fs, lfp_trial_ind):\n",
    "    \"\"\"This function specifically: finds troughs in the phase time Series, \n",
    "    and adds the trough-based cycle labels to the available dataframe \n",
    "    df: dataframe, need to make sure that if this is a subset of another DataFrame\n",
    "    you pass in the subdf.reset_index() version, so that the cycle labels can be\n",
    "    assigned for the corresponding indices\"\"\"\n",
    "    \n",
    "   # find the troughs\n",
    "    troughs, _ = find_peaks(df[filtcol],\n",
    "                            height=None,\n",
    "                            threshold=None,\n",
    "                            distance=None,\n",
    "                            prominence=None,\n",
    "                            width=None,\n",
    "                            wlen=None,\n",
    "                            rel_height=0.5,\n",
    "                            plateau_size=None)\n",
    "\n",
    "    cycle_bin_edges = np.hstack((0,troughs[0],troughs[1:],df.shape[0]))\n",
    "\n",
    "    ncycles = len(troughs)+1\n",
    "    cycle_labels = np.arange(0,ncycles)\n",
    "\n",
    "    df = df.reset_index()\n",
    "    df['cycle_labels'] = pd.cut(df.index,\n",
    "                                bins=cycle_bin_edges,\n",
    "                                labels=cycle_labels,\n",
    "                                include_lowest=True\n",
    "                                     )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5058924a",
   "metadata": {},
   "source": [
    "### load the fit models\n",
    "which you set up in notebook `final_fit_kde_models.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a622614",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = 'kde_models_ints_odorsamp/'\n",
    "files = os.listdir(modelpath)\n",
    "files = [f for f in files if not f.startswith('.')]\n",
    "files = sorted(files)\n",
    "\n",
    "#first, put all the kde dfs together\n",
    "kde_odor = []\n",
    "for file in files: \n",
    "    \n",
    "    model_df = pd.read_csv(os.path.join(modelpath,file))\n",
    "    \n",
    "    kde_odor.append(model_df)\n",
    "    \n",
    "kde_odor = pd.concat(kde_odor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a567ac",
   "metadata": {},
   "source": [
    "Take a look at the models by rhythm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2f3504",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_labels_odor = list(set(kde_odor['cell_id'].tolist()))\n",
    "rhythm_labels = ['theta','beta','lowgamma','highgamma']\n",
    "x = np.linspace(-np.pi,np.pi,1000)\n",
    "\n",
    "fig,ax=plt.subplots(1,4,figsize=(20,4))\n",
    "\n",
    "for cell_odor in tqdm(cell_labels_odor):  \n",
    "    \n",
    "    subcell_odor = kde_odor[kde_odor['cell_id'] == cell_odor]\n",
    "    quarter_labels = list(set(subcell_odor['quarter_labels'].tolist()))\n",
    "    \n",
    "    for q in quarter_labels:\n",
    "   \n",
    "        subq = subcell_odor[subcell_odor['quarter_labels'] == q]\n",
    "        condition_labels = list(set(subq['condition_labels']))\n",
    "    \n",
    "        for condition in condition_labels: \n",
    "            \n",
    "            subc = subq[subq['condition_labels']==condition]\n",
    "            \n",
    "            for i,rhythm in enumerate(rhythm_labels):\n",
    "\n",
    "                subrh_odor = subc[subc['rhythm'] == rhythm]\n",
    "                ax[i].plot(x,subrh_odor['kde_spikeprob'].values,color='grey',alpha=0.6)\n",
    "                ax[i].set_title(rhythm)\n",
    "\n",
    "for ax in ax.flatten():\n",
    "    ax.set_ylim(0, .095)\n",
    "\n",
    "        \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df7e6ea",
   "metadata": {},
   "source": [
    "### generate a unique identifier for each odor-context spike train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b17cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate unique identifier for each odor's spike train (e.g. each neuron at most gets 8 different\n",
    "#numbers)\n",
    "cell_labels_odor = list(set(kde_odor['cell_id'].tolist()))\n",
    "counter = 0\n",
    "gather_dfs = []\n",
    "for cell in cell_labels_odor:\n",
    "    \n",
    "    subcell_odor = kde_odor[kde_odor['cell_id'] == cell]\n",
    "    quarter_labels = list(set(subcell_odor['quarter_labels'].tolist()))\n",
    "    for q in quarter_labels:\n",
    "        subq = subcell_odor[subcell_odor['quarter_labels'] == q]\n",
    "        \n",
    "        condition_labels = list(set(subq['condition_labels']))\n",
    "        \n",
    "        for condition in condition_labels: \n",
    "            subc = subq[subq['condition_labels']==condition]\n",
    "            \n",
    "            spktrn_ind_labels = np.repeat(counter,subc.shape[0])\n",
    "            subc['spktrn_ind_labels'] = spktrn_ind_labels[0]\n",
    "\n",
    "            gather_dfs.append(subc)\n",
    "            counter += 1\n",
    "\n",
    "kde_odor = pd.concat(gather_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6ecdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_spktrns = kde_odor['spktrn_ind_labels'].max() + 1 #remember 0 indexing, this is just the largest\n",
    "                                                #label, later, you will add 1 to get the actual\n",
    "                                                #number of spike trains included!\n",
    "        \n",
    "print('number of spike trains: ',n_spktrns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0b067c",
   "metadata": {},
   "source": [
    "###### center phase models\n",
    "To visually compare across models, you will center the phase models according to each curve's own mean probability of spiking. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bc79f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ODORSAMPLING \n",
    "# here is where you center each kde curve according to its own mean\n",
    "x = np.linspace(-np.pi,np.pi,1000)\n",
    "\n",
    "theta_kde_odor = np.zeros((n_spktrns+1,len(x)))\n",
    "lowgamma_kde_odor = np.zeros((n_spktrns+1,len(x)))\n",
    "highgamma_kde_odor = np.zeros((n_spktrns+1,len(x)))\n",
    "\n",
    "theta_kde_cent_odor = np.zeros((n_spktrns+1,len(x)))\n",
    "lowgamma_kde_cent_odor = np.zeros((n_spktrns+1,len(x)))\n",
    "highgamma_kde_cent_odor = np.zeros((n_spktrns+1,len(x)))\n",
    "\n",
    "spktrn_index_labels = list(set(kde_odor['spktrn_ind_labels'].to_list()))\n",
    "for index in tqdm(spktrn_index_labels):\n",
    "    \n",
    "    for rhythm in rhythm_labels:\n",
    "        \n",
    "        subcellrh = kde_odor[(kde_odor['rhythm'] == rhythm) & (kde_odor['spktrn_ind_labels'] == index)]\n",
    "        \n",
    "        if rhythm=='theta':\n",
    "            \n",
    "            theta_kde_odor[index] = subcellrh['kde_spikeprob'].values\n",
    "            theta_kde_cent_odor[index] = theta_kde_odor[index] - theta_kde_odor[index].mean()\n",
    "            \n",
    "        if rhythm=='lowgamma':\n",
    "            \n",
    "            lowgamma_kde_odor[index] = subcellrh['kde_spikeprob'].values\n",
    "            lowgamma_kde_cent_odor[index] = lowgamma_kde_odor[index] - lowgamma_kde_odor[index].mean()\n",
    "            \n",
    "        if rhythm=='highgamma':    \n",
    "            \n",
    "            highgamma_kde_odor[index] = subcellrh['kde_spikeprob'].values\n",
    "            highgamma_kde_cent_odor[index] = highgamma_kde_odor[index] - highgamma_kde_odor[index].mean()\n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2235d7",
   "metadata": {},
   "source": [
    "### compute the sum kld and Rayleigh statistics\n",
    "On the raw (non-centered models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d36b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 7 #corresponds to the number of CV folds used to find the optimal \n",
    "             #kernel bandwidth for fitting. this is also the minimal number of spikes\n",
    "             #that a neuron had to have in an odor-context spike train to be able to fit \n",
    "             #the kde models using 7-fold CV\n",
    "rhythms = ['theta','lowgamma','highgamma']\n",
    "\n",
    "datapath = 'python_spkphase_odorsamp/'\n",
    "files = os.listdir(datapath)\n",
    "files = [f for f in files if not f.startswith('.')]\n",
    "files = sorted(files)\n",
    "\n",
    "sumkld_df = [] #initialize the df that will contain all the files' data\n",
    "for file in tqdm(files, position=0, desc=\"file\", leave=True, colour='cornflowerblue'): \n",
    " \n",
    "    df = pd.read_csv(os.path.join(datapath,file))\n",
    "    odorsamp_df = df[df['trial_segment']=='dur']\n",
    "\n",
    "    df = [] #clear out to save memory\n",
    "\n",
    "    quarters = list(set(odorsamp_df['quarter_labels']))\n",
    "\n",
    "    for quarter in tqdm(quarters,position=1,desc='quarter',leave=False,colour='lavender'): \n",
    "    \n",
    "        subq = odorsamp_df[odorsamp_df['quarter_labels']==quarter]\n",
    "\n",
    "        if np.all(subq['accuracy'] >= .75):\n",
    "            \n",
    "            neuron_cols = get_neuron_cols(subq,'TETSPK')\n",
    "            \n",
    "            for rhythm in tqdm(rhythms,position=2,desc='rhythm',leave=False,colour='hotpink'): \n",
    "\n",
    "                for neuron in tqdm(neuron_cols,position=3,desc='neuron',leave=False,colour='mediumturquoise'): \n",
    "\n",
    "                    cell_id = file.split('_')[0] + '_' + file.split('_')[1] + '_' + neuron\n",
    "\n",
    "                    allow_wire = get_allowable_lfp_wires(neuron,'K')\n",
    "\n",
    "                    #grab the lfps\n",
    "                    lfp_cols = get_lfp_cols(subq,\"TETFP\"+allow_wire[0]+\"\\Z|TETFP\"+allow_wire[1]+\"\\Z|TETFP\"+allow_wire[2]+\"\\Z|TETFP\"+allow_wire[3]+\"\\Z\")\n",
    "                    lfp_name = lfp_cols[0]\n",
    "\n",
    "                    #create the phase columns using the hilbert transform on the filtered lfp\n",
    "                    filt_name = lfp_name + 'filt_' + rhythm \n",
    "\n",
    "                    filtered = subq[filt_name]\n",
    "                    analytic_signal = hilbert(filtered)\n",
    "\n",
    "                    phase_name = lfp_name + 'phase_' + rhythm \n",
    "                    subq[phase_name] = np.arctan2(filtered,analytic_signal.imag);\n",
    "\n",
    "                    #get the unique odor position identifiers for each condition\n",
    "                    condition_labels = subq.groupby(['odor_labels']).sum().index\n",
    "                    \n",
    "                    for condition in condition_labels:\n",
    "\n",
    "                        #need to filter the dataset by condition now\n",
    "                        odor = condition\n",
    "   \n",
    "                        d = subq[(subq['odor_labels']==odor)]\n",
    "\n",
    "                        #now, grab the spikes and phases to fit the kde curves\n",
    "                        #grab data\n",
    "                        spikes = d[neuron].values\n",
    "                        phases = d[phase_name].values\n",
    "\n",
    "                        phi_when_sp = []\n",
    "                        for s,p in zip(spikes,phases):\n",
    "                            if s==1: \n",
    "                                phi_when_sp.append(p)\n",
    "\n",
    "                        phi_when_sp = np.array(phi_when_sp)\n",
    "                        \n",
    "                        df_for_ray = pd.DataFrame() #initialize dataframe for the rayleigh code\n",
    "\n",
    "                        #CRITERION: number of spikes must exceed the number of cross val splits for fitting kde\n",
    "                        if n_splits < sum(spikes):\n",
    "                            \n",
    "                            subcellrh = kde_odor[(kde_odor['cell_id']==cell_id) & (kde_odor['rhythm']==rhythm) & (kde_odor['condition_labels']==odor)]\n",
    "\n",
    "                            # compute the kld(phase model || uniform spiking) per cell, per rhythm\n",
    "                            avgspk = d[neuron].sum()/d.shape[0]\n",
    "                            uni_pspk = np.repeat(avgspk,subcellrh.shape[0])\n",
    "\n",
    "                            df_for_ray['spikes'] = spikes\n",
    "                            df_for_ray[rhythm+'_phases'] = phases\n",
    "                            ray = rayleigh_pr(df_for_ray, rhythm)\n",
    "\n",
    "                            sumkl = np.sum(kl(subcellrh['kde_spikeprob'].values,uni_pspk))\n",
    "                            sumkld = {'cell_id': cell_id,\n",
    "                                      'quarter_labels': quarter,\n",
    "                                      'condition_labels': odor,\n",
    "                                      'sumkld': sumkl,\n",
    "                                      'ray_mrl': ray['mrl'].values,\n",
    "                                      'ray_pval': ray['pval'].values,\n",
    "                                      'ray_circmean': ray['circmean'].values,\n",
    "                                      'frate': avgspk*1000,\n",
    "                                      'rhythm': rhythm,\n",
    "                                      'spktrn_ind_labels': subcellrh['spktrn_ind_labels'].iloc[0]\n",
    "                                          }\n",
    "\n",
    "                            sumkld_df.append(pd.DataFrame(sumkld))\n",
    "\n",
    "sumkld_df = pd.concat(sumkld_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cdb9c7",
   "metadata": {},
   "source": [
    "## cluster the odor-context spike trains\n",
    "according to their spike phase relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77774d61",
   "metadata": {},
   "source": [
    "##### set up clustering parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03717e85",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sumkld_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/95/7z0h1t9s5tx7km1h1t7t08kw0000gn/T/ipykernel_2826/949830459.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.05\u001b[0m \u001b[0;31m#p < alpha for Rayleigh statistical significance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msumkld_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'significant'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msumkld_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ray_pval'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sumkld_df' is not defined"
     ]
    }
   ],
   "source": [
    "alpha = 0.05 #p < alpha for Rayleigh statistical significance\n",
    "\n",
    "sumkld_df['significant'] = [1 if (i < alpha) else 0 for i in sumkld_df['ray_pval'].values]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5c0397",
   "metadata": {},
   "source": [
    "Each rhythm gets its own phase boundaries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132a9dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#theta\n",
    "phase_thresh02 = -3\n",
    "phase_thresh0 = -1\n",
    "phase_thresh2 = 1.5\n",
    "\n",
    "\n",
    "subtheta_sig = sumkld_df[(sumkld_df['rhythm'] == 'theta') & (sumkld_df['significant'] == 1)]\n",
    "subtheta_nosig = sumkld_df[(sumkld_df['rhythm'] == 'theta') & (sumkld_df['significant'] == 0)]\n",
    "\n",
    "cluster0 = subtheta_sig[(subtheta_sig['ray_circmean'] > phase_thresh02) & (subtheta_sig['ray_circmean'] < phase_thresh0)].reset_index()\n",
    "cluster1 = subtheta_sig[(subtheta_sig['ray_circmean'] >= phase_thresh0) & (subtheta_sig['ray_circmean'] <= phase_thresh2)].reset_index()\n",
    "cluster2a = subtheta_sig[(subtheta_sig['ray_circmean'] > phase_thresh2)].reset_index()\n",
    "cluster2b = subtheta_sig[(subtheta_sig['ray_circmean'] <= phase_thresh02)].reset_index()\n",
    "cluster2 = pd.concat([cluster2a,cluster2b])\n",
    "cluster3 = subtheta_nosig.reset_index()\n",
    "\n",
    "cluster0['theta_clust_id'] = np.repeat(0,cluster0.shape[0])\n",
    "cluster1['theta_clust_id'] = np.repeat(1,cluster1.shape[0])\n",
    "cluster2['theta_clust_id'] = np.repeat(2,cluster2.shape[0])\n",
    "cluster3['theta_clust_id'] = np.repeat(3,cluster3.shape[0])\n",
    "\n",
    "theta_cluster_id_df = pd.concat([cluster0,cluster1,cluster2,cluster3])\n",
    "\n",
    "#lowgamma\n",
    "\n",
    "sublowgamma_sig = sumkld_df[(sumkld_df['rhythm'] == 'lowgamma') & (sumkld_df['significant'] == 1)]\n",
    "sublowgamma_nosig = sumkld_df[(sumkld_df['rhythm'] == 'lowgamma') & (sumkld_df['significant'] == 0)]\n",
    "\n",
    "phase_threshleft = -2\n",
    "phase_threshright = 2\n",
    "phase_threshmidright = 0.4\n",
    "\n",
    "cluster0a = sublowgamma_sig[(sublowgamma_sig['ray_circmean'] < phase_threshleft)].reset_index()\n",
    "cluster0b = sublowgamma_sig[(sublowgamma_sig['ray_circmean'] > phase_threshright)].reset_index()\n",
    "cluster0 = pd.concat([cluster0a,cluster0b])\n",
    "cluster1 = sublowgamma_sig[(sublowgamma_sig['ray_circmean'] >= phase_threshleft) & (sublowgamma_sig['ray_circmean'] <= phase_threshmidright)].reset_index()\n",
    "cluster2 = sublowgamma_sig[(sublowgamma_sig['ray_circmean'] > phase_threshmidright) & (sublowgamma_sig['ray_circmean'] <= phase_threshright)].reset_index()\n",
    "cluster3 = sublowgamma_nosig.reset_index()\n",
    "\n",
    "cluster0['lowgamma_clust_id'] = np.repeat(0,cluster0.shape[0])\n",
    "cluster1['lowgamma_clust_id'] = np.repeat(1,cluster1.shape[0])\n",
    "cluster2['lowgamma_clust_id'] = np.repeat(2,cluster2.shape[0])\n",
    "cluster3['lowgamma_clust_id'] = np.repeat(3,cluster3.shape[0])\n",
    "\n",
    "lowgamma_cluster_id_df = pd.concat([cluster0,cluster1,cluster2,cluster3])\n",
    "\n",
    "\n",
    "#highgamma\n",
    "\n",
    "subhighgamma_sig = sumkld_df[(sumkld_df['rhythm'] == 'highgamma') & (sumkld_df['significant'] == 1)]\n",
    "subhighgamma_nosig = sumkld_df[(sumkld_df['rhythm'] == 'highgamma') & (sumkld_df['significant'] == 0)]\n",
    "\n",
    "phase_thresh01 = -1.5\n",
    "phase_thresh10 = 1\n",
    "\n",
    "cluster0a = subhighgamma_sig[(subhighgamma_sig['ray_circmean'] < phase_thresh01)].reset_index()\n",
    "cluster0b = subhighgamma_sig[(subhighgamma_sig['ray_circmean'] > phase_thresh10)].reset_index()\n",
    "cluster0 = pd.concat([cluster0a,cluster0b])\n",
    "cluster1 = subhighgamma_sig[(subhighgamma_sig['ray_circmean'] >= phase_thresh01) & (subhighgamma_sig['ray_circmean'] <= phase_thresh10)].reset_index()\n",
    "cluster2 = subhighgamma_nosig.reset_index()\n",
    "\n",
    "cluster0['highgamma_clust_id'] = np.repeat(0,cluster0.shape[0])\n",
    "cluster1['highgamma_clust_id'] = np.repeat(1,cluster1.shape[0])\n",
    "cluster2['highgamma_clust_id'] = np.repeat(2,cluster2.shape[0])\n",
    "\n",
    "highgamma_cluster_id_df = pd.concat([cluster0,cluster1,cluster2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa944987",
   "metadata": {},
   "source": [
    "Now merge the dataframes containing cluster identity information for each rhythm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0793c2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_id_df = theta_cluster_id_df.merge(highgamma_cluster_id_df,on=['cell_id','quarter_labels','condition_labels','spktrn_ind_labels'],suffixes=('_theta','_highgamma'))\n",
    "cluster_id_df = cluster_id_df.merge(lowgamma_cluster_id_df,on=['cell_id','quarter_labels','condition_labels','spktrn_ind_labels'],suffixes=('_theta','_highgamma','_lowgamma'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf0e76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_clust_id_df = cluster_id_df[['cell_id',\n",
    "                                     'condition_labels',\n",
    "                                     'spktrn_ind_labels',\n",
    "                                     'theta_clust_id',\n",
    "                                     'lowgamma_clust_id',\n",
    "                                     'highgamma_clust_id'\n",
    "                                    ]]\n",
    "\n",
    "# save this reduced_clust_id_df for analyses in different notebooks\n",
    "reduced_clust_id_df.to_csv('cluster_ids_theta_lowgamma_highgamma.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61c8657",
   "metadata": {},
   "source": [
    "### Figure 2A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699de28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(3,1,figsize=(12,10))\n",
    "\n",
    "#theta \n",
    "\n",
    "sns.scatterplot(data=cluster_id_df,\n",
    "                x='ray_circmean_theta',\n",
    "                y='sumkld_theta',\n",
    "                hue='theta_clust_id',\n",
    "                palette=['firebrick','dodgerblue','gold','turquoise'],\n",
    "                alpha=0.5,\n",
    "                s=80,\n",
    "                ax=ax[0]\n",
    "               )\n",
    "\n",
    "circmeans0 = cluster_id_df[cluster_id_df['theta_clust_id']==0]['ray_circmean_theta']\n",
    "mean0 = compute_circmean(circmeans0)\n",
    "ax[0].vlines(x=mean0,ymin=0,ymax=6,color='firebrick',linestyle='--',linewidth=4)\n",
    "\n",
    "circmeans1 = cluster_id_df[cluster_id_df['theta_clust_id']==1]['ray_circmean_theta']\n",
    "mean1 = compute_circmean(circmeans1)\n",
    "ax[0].vlines(x=mean1,ymin=0,ymax=6,color='dodgerblue',linestyle='--',linewidth=4)\n",
    "\n",
    "circmeans2 = cluster_id_df[cluster_id_df['theta_clust_id']==2]['ray_circmean_theta']\n",
    "mean2 = compute_circmean(circmeans2)\n",
    "ax[0].vlines(x=mean2,ymin=0,ymax=6,color='gold',linestyle='--',linewidth=4)\n",
    "\n",
    "print('theta centroids: \\n',\n",
    "      'centroid 0: ', mean0,'\\n',\n",
    "      'centroid 1: ', mean1,'\\n',\n",
    "      'centroid 2: ', mean2\n",
    "     )\n",
    "\n",
    "ax[0].set_xlim(-np.pi,np.pi)\n",
    "ax[0].legend(fontsize=10)\n",
    "\n",
    "#lowgamma \n",
    "\n",
    "sns.scatterplot(data=cluster_id_df,\n",
    "                x='ray_circmean',\n",
    "                y='sumkld',\n",
    "                hue='lowgamma_clust_id',\n",
    "                palette=['gold','goldenrod','olive','palegoldenrod'],\n",
    "                alpha=0.5,\n",
    "                s=80,\n",
    "                ax=ax[1]\n",
    "               )\n",
    "\n",
    "circmeans0 = cluster_id_df[cluster_id_df['lowgamma_clust_id']==0]['ray_circmean']\n",
    "mean0 = compute_circmean(circmeans0)\n",
    "ax[1].vlines(x=mean0,ymin=0,ymax=6,color='gold',linestyle='--',linewidth=4)\n",
    "\n",
    "circmeans1 = cluster_id_df[cluster_id_df['lowgamma_clust_id']==1]['ray_circmean']\n",
    "mean1 = compute_circmean(circmeans1)\n",
    "ax[1].vlines(x=mean1,ymin=0,ymax=6,color='goldenrod',linestyle='--',linewidth=4)\n",
    "\n",
    "circmeans2 = cluster_id_df[cluster_id_df['lowgamma_clust_id']==2]['ray_circmean']\n",
    "mean2 = compute_circmean(circmeans2)\n",
    "ax[1].vlines(x=mean2,ymin=0,ymax=6,color='olive',linestyle='--',linewidth=4)\n",
    "\n",
    "\n",
    "ax[1].set_xlim(-np.pi,np.pi)\n",
    "ax[1].legend(fontsize=10)\n",
    "\n",
    "print('lowgamma centroids: \\n',\n",
    "      'centroid 0: ', mean0,'\\n',\n",
    "      'centroid 1: ', mean1,'\\n',\n",
    "      'centroid 2: ', mean2\n",
    "     )\n",
    "\n",
    "#highgamma\n",
    "\n",
    "sns.scatterplot(data=cluster_id_df,\n",
    "                x='ray_circmean_highgamma',\n",
    "                y='sumkld_highgamma',\n",
    "                hue='highgamma_clust_id',\n",
    "                alpha=0.5,\n",
    "                s=80,\n",
    "                ax=ax[2]\n",
    "               )\n",
    "\n",
    "circmeans0 = cluster_id_df[cluster_id_df['highgamma_clust_id']==0]['ray_circmean_highgamma']\n",
    "mean0 = compute_circmean(circmeans0)\n",
    "ax[2].vlines(x=mean0,ymin=0,ymax=6,color='lightpink',linestyle='--',linewidth=4)\n",
    "\n",
    "circmeans1 = cluster_id_df[cluster_id_df['highgamma_clust_id']==1]['ray_circmean_highgamma']\n",
    "mean1 = compute_circmean(circmeans1)\n",
    "ax[2].vlines(x=mean1,ymin=0,ymax=6,color='thistle',linestyle='--',linewidth=4)\n",
    "\n",
    "\n",
    "ax[2].set_xlim(-np.pi,np.pi)\n",
    "ax[2].legend(fontsize=10)\n",
    "\n",
    "print('highgamma centroids: \\n',\n",
    "      'centroid 0: ', mean0,'\\n',\n",
    "      'centroid 1: ', mean1)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cfc4b5",
   "metadata": {},
   "source": [
    "#### find the location of centroids for each cluster \n",
    "ignoring the uniform cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e65a09",
   "metadata": {},
   "source": [
    "__theta__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52995c44",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "circmeans0 = cluster_id_df[cluster_id_df['theta_clust_id']==0]['ray_circmean_theta']\n",
    "mean0 = compute_circmean(circmeans0)\n",
    "circmeans1 = cluster_id_df[cluster_id_df['theta_clust_id']==1]['ray_circmean_theta']\n",
    "mean1 = compute_circmean(circmeans1)\n",
    "circmeans2 = cluster_id_df[cluster_id_df['theta_clust_id']==2]['ray_circmean_theta']\n",
    "mean2 = compute_circmean(circmeans2)\n",
    "\n",
    "print(mean0, mean1, mean2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64fe285",
   "metadata": {},
   "source": [
    "### Figure 2B (top row)\n",
    "Visualize the mean-centered phase models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a89117e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='whitegrid',font_scale=1.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70891de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(4,4,figsize=(20,15))\n",
    "\n",
    "## CLUST 0\n",
    "rhythm = 'theta'\n",
    "subclust = cluster_id_df[cluster_id_df['theta_clust_id'] == 0]\n",
    "inds = subclust['spktrn_ind_labels'].values\n",
    "ax[0][0].plot(x,theta_kde_cent_odor[inds,:].T,color='firebrick');\n",
    "ax[0][0].set_title('theta')\n",
    "\n",
    "ax[0][1].plot(x,beta_kde_cent_odor[inds,:].T,color='grey');\n",
    "ax[0][1].set_title('beta')\n",
    "\n",
    "ax[0][2].plot(x,lowgamma_kde_cent_odor[inds,:].T,color='grey');\n",
    "ax[0][2].set_title('lowgamma')\n",
    "\n",
    "ax[0][3].plot(x,highgamma_kde_cent_odor[inds,:].T,color='grey');\n",
    "ax[0][3].set_title('highgamma')\n",
    "\n",
    "\n",
    "## CLUST 1\n",
    "\n",
    "rhythm = 'theta'\n",
    "subclust = cluster_id_df[cluster_id_df['theta_clust_id'] == 1]\n",
    "inds = subclust['spktrn_ind_labels'].values\n",
    "ax[1][0].plot(x,theta_kde_cent_odor[inds,:].T,color='dodgerblue');\n",
    "ax[1][0].set_title('theta')\n",
    "\n",
    "ax[1][1].plot(x,beta_kde_cent_odor[inds,:].T,color='grey');\n",
    "ax[1][1].set_title('beta')\n",
    "\n",
    "ax[1][2].plot(x,lowgamma_kde_cent_odor[inds,:].T,color='grey');\n",
    "ax[1][2].set_title('lowgamma')\n",
    "\n",
    "ax[1][3].plot(x,highgamma_kde_cent_odor[inds,:].T,color='grey');\n",
    "ax[1][3].set_title('highgamma')\n",
    "\n",
    "#CLUST 2\n",
    "\n",
    "rhythm = 'theta'\n",
    "subclust = cluster_id_df[cluster_id_df['theta_clust_id'] == 2]\n",
    "inds = subclust['spktrn_ind_labels'].values\n",
    "ax[2][0].plot(x,theta_kde_cent_odor[inds,:].T,color='gold');\n",
    "ax[2][0].set_title('theta')\n",
    "\n",
    "ax[2][1].plot(x,beta_kde_cent_odor[inds,:].T,color='grey');\n",
    "ax[2][1].set_title('beta')\n",
    "\n",
    "ax[2][2].plot(x,lowgamma_kde_cent_odor[inds,:].T,color='grey');\n",
    "ax[2][2].set_title('lowgamma')\n",
    "\n",
    "ax[2][3].plot(x,highgamma_kde_cent_odor[inds,:].T,color='grey');\n",
    "ax[2][3].set_title('highgamma')\n",
    "\n",
    "\n",
    "## CLUST 3\n",
    "rhythm = 'theta'\n",
    "subclust = cluster_id_df[cluster_id_df['theta_clust_id'] == 3]\n",
    "inds = subclust['spktrn_ind_labels'].values\n",
    "ax[3][0].plot(x,theta_kde_cent_odor[inds,:].T,color='turquoise');\n",
    "ax[3][0].set_title('theta')\n",
    "\n",
    "ax[3][1].plot(x,beta_kde_cent_odor[inds,:].T,color='grey');\n",
    "ax[3][1].set_title('beta')\n",
    "\n",
    "ax[3][2].plot(x,lowgamma_kde_cent_odor[inds,:].T,color='grey');\n",
    "ax[3][2].set_title('lowgamma')\n",
    "\n",
    "ax[3][3].plot(x,highgamma_kde_cent_odor[inds,:].T,color='grey');\n",
    "ax[3][3].set_title('highgamma')\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "for ax in ax.flatten():\n",
    "    ax.set_ylim(-0.045, .045)\n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39664a46",
   "metadata": {},
   "source": [
    "##### find the fraction of spike trains per theta cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e9d4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CLUST 0\n",
    "rhythm = 'theta'\n",
    "subclust = cluster_id_df[cluster_id_df['theta_clust_id'] == 0]\n",
    "clust0_inds = subclust['spktrn_ind_labels'].values\n",
    "\n",
    "clust0_number = len(clust0_inds)\n",
    "clust0_fraction = len(clust0_inds)/n_spktrns\n",
    "\n",
    "## CLUST 1\n",
    "rhythm = 'theta'\n",
    "subclust = cluster_id_df[cluster_id_df['theta_clust_id'] == 1]\n",
    "clust1_inds = subclust['spktrn_ind_labels'].values\n",
    "\n",
    "clust1_number = len(clust1_inds)\n",
    "clust1_fraction = len(clust1_inds)/n_spktrns\n",
    "\n",
    "#CLUST 2\n",
    "\n",
    "rhythm = 'theta'\n",
    "subclust = cluster_id_df[cluster_id_df['theta_clust_id'] == 2]\n",
    "clust2_inds = subclust['spktrn_ind_labels'].values\n",
    "\n",
    "clust2_number = len(clust2_inds)\n",
    "clust2_fraction = len(clust2_inds)/n_spktrns\n",
    "\n",
    "#CLUST 3\n",
    "\n",
    "rhythm = 'theta'\n",
    "subclust = cluster_id_df[cluster_id_df['theta_clust_id'] == 3]\n",
    "clust3_inds = subclust['spktrn_ind_labels'].values\n",
    "\n",
    "clust3_number = len(clust3_inds)\n",
    "clust3_fraction = len(clust3_inds)/n_spktrns\n",
    "\n",
    "print('clust0: ', clust0_fraction, 'n= ', clust0_number,\n",
    "      '\\nclust1: ', clust1_fraction, 'n= ', clust1_number,\n",
    "      '\\nclust2: ' , clust2_fraction,'n= ', clust2_number, \n",
    "      '\\nclust3: ', clust3_fraction, 'n= ', clust3_number\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a3d14e",
   "metadata": {},
   "source": [
    "### Figure 2B (middle row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c125291",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(4,4,figsize=(20,15))\n",
    "\n",
    "## CLUST 0\n",
    "rhythm = 'lowgamma'\n",
    "subclust = cluster_id_df[cluster_id_df['lowgamma_clust_id'] == 0]\n",
    "inds = subclust['spktrn_ind_labels'].values\n",
    "ax[0][0].plot(x,theta_kde_cent_odor[inds,:].T,color='grey');\n",
    "ax[0][0].set_title('theta')\n",
    "\n",
    "ax[0][1].plot(x,beta_kde_cent_odor[inds,:].T,color='grey');\n",
    "ax[0][1].set_title('beta')\n",
    "\n",
    "ax[0][2].plot(x,lowgamma_kde_cent_odor[inds,:].T,color='gold');\n",
    "ax[0][2].set_title('lowgamma')\n",
    "\n",
    "ax[0][3].plot(x,highgamma_kde_cent_odor[inds,:].T,color='grey');\n",
    "ax[0][3].set_title('highgamma')\n",
    "\n",
    "\n",
    "## CLUST 1\n",
    "\n",
    "rhythm = 'lowgamma'\n",
    "subclust = cluster_id_df[cluster_id_df['lowgamma_clust_id'] == 1]\n",
    "inds = subclust['spktrn_ind_labels'].values\n",
    "ax[1][0].plot(x,theta_kde_cent_odor[inds,:].T,color='grey');\n",
    "ax[1][0].set_title('theta')\n",
    "\n",
    "ax[1][1].plot(x,beta_kde_cent_odor[inds,:].T,color='grey');\n",
    "ax[1][1].set_title('beta')\n",
    "\n",
    "ax[1][2].plot(x,lowgamma_kde_cent_odor[inds,:].T,color='goldenrod');\n",
    "ax[1][2].set_title('lowgamma')\n",
    "\n",
    "ax[1][3].plot(x,highgamma_kde_cent_odor[inds,:].T,color='grey');\n",
    "ax[1][3].set_title('highgamma')\n",
    "\n",
    "#CLUST 2\n",
    "\n",
    "rhythm = 'lowgamma'\n",
    "subclust = cluster_id_df[cluster_id_df['lowgamma_clust_id'] == 2]\n",
    "inds = subclust['spktrn_ind_labels'].values\n",
    "ax[2][0].plot(x,theta_kde_cent_odor[inds,:].T,color='grey');\n",
    "ax[2][0].set_title('theta')\n",
    "\n",
    "ax[2][1].plot(x,beta_kde_cent_odor[inds,:].T,color='grey');\n",
    "ax[2][1].set_title('beta')\n",
    "\n",
    "ax[2][2].plot(x,lowgamma_kde_cent_odor[inds,:].T,color='olive');\n",
    "ax[2][2].set_title('lowgamma')\n",
    "\n",
    "ax[2][3].plot(x,highgamma_kde_cent_odor[inds,:].T,color='grey');\n",
    "ax[2][3].set_title('highgamma')\n",
    "\n",
    "\n",
    "## CLUST 3\n",
    "rhythm = 'lowgamma'\n",
    "subclust = cluster_id_df[cluster_id_df['lowgamma_clust_id'] == 3]\n",
    "inds = subclust['spktrn_ind_labels'].values\n",
    "ax[3][0].plot(x,theta_kde_cent_odor[inds,:].T,color='grey');\n",
    "ax[3][0].set_title('theta')\n",
    "\n",
    "ax[3][1].plot(x,beta_kde_cent_odor[inds,:].T,color='grey');\n",
    "ax[3][1].set_title('beta')\n",
    "\n",
    "ax[3][2].plot(x,lowgamma_kde_cent_odor[inds,:].T,color='palegoldenrod');\n",
    "ax[3][2].set_title('lowgamma')\n",
    "\n",
    "ax[3][3].plot(x,highgamma_kde_cent_odor[inds,:].T,color='grey');\n",
    "ax[3][3].set_title('highgamma')\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "for ax in ax.flatten():\n",
    "    ax.set_ylim(-0.045, .045)\n",
    "    \n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780fc144",
   "metadata": {},
   "source": [
    "##### find the fraction of spike trains per low gamma cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5558f3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CLUST 0\n",
    "rhythm = 'lowgamma'\n",
    "subclust = cluster_id_df[cluster_id_df['lowgamma_clust_id'] == 0]\n",
    "inds = subclust['spktrn_ind_labels'].values\n",
    "\n",
    "clust0_number = len(inds)\n",
    "clust0_fraction = clust0_number/n_spktrns\n",
    "\n",
    "## CLUST 1\n",
    "\n",
    "rhythm = 'lowgamma'\n",
    "subclust = cluster_id_df[cluster_id_df['lowgamma_clust_id'] == 1]\n",
    "inds = subclust['spktrn_ind_labels'].values\n",
    "\n",
    "clust1_number = len(inds)\n",
    "clust1_fraction = clust1_number/n_spktrns\n",
    "\n",
    "#CLUST 2\n",
    "\n",
    "rhythm = 'lowgamma'\n",
    "subclust = cluster_id_df[cluster_id_df['lowgamma_clust_id'] == 2]\n",
    "inds = subclust['spktrn_ind_labels'].values\n",
    "\n",
    "clust2_number = len(inds)\n",
    "clust2_fraction = clust2_number/n_spktrns\n",
    "\n",
    "## CLUST 3\n",
    "rhythm = 'lowgamma'\n",
    "subclust = cluster_id_df[cluster_id_df['lowgamma_clust_id'] == 3]\n",
    "inds = subclust['spktrn_ind_labels'].values\n",
    "\n",
    "clust3_number = len(inds)\n",
    "clust3_fraction = clust3_number/n_spktrns\n",
    "\n",
    "print('clust0: ', clust0_fraction, 'n= ', clust0_number,\n",
    "      '\\nclust1: ', clust1_fraction, 'n= ', clust1_number,\n",
    "      '\\nclust2: ' , clust2_fraction,'n= ', clust2_number, \n",
    "      '\\nclust3: ', clust3_fraction, 'n= ', clust3_number\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd966392",
   "metadata": {},
   "source": [
    "### Figure 2B (bottom row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb933f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(3,4,figsize=(20,13))\n",
    "\n",
    "## CLUST 0\n",
    "rhythm = 'highgamma'\n",
    "subclust = cluster_id_df[cluster_id_df['highgamma_clust_id'] == 0]\n",
    "inds = subclust['spktrn_ind_labels'].values\n",
    "ax[0][0].plot(x,theta_kde_cent_odor[inds,:].T,color='grey');\n",
    "ax[0][0].set_title('theta')\n",
    "\n",
    "ax[0][1].plot(x,beta_kde_cent_odor[inds,:].T,color='grey');\n",
    "ax[0][1].set_title('beta')\n",
    "\n",
    "ax[0][2].plot(x,lowgamma_kde_cent_odor[inds,:].T,color='grey');\n",
    "ax[0][2].set_title('lowgamma')\n",
    "\n",
    "ax[0][3].plot(x,highgamma_kde_cent_odor[inds,:].T,color='mediumslateblue');\n",
    "ax[0][3].set_title('highgamma')\n",
    "\n",
    "\n",
    "## CLUST 1\n",
    "\n",
    "rhythm = 'highgamma'\n",
    "subclust = cluster_id_df[cluster_id_df['highgamma_clust_id'] == 1]\n",
    "inds = subclust['spktrn_ind_labels'].values\n",
    "ax[1][0].plot(x,theta_kde_cent_odor[inds,:].T,color='grey');\n",
    "ax[1][0].set_title('theta')\n",
    "\n",
    "ax[1][1].plot(x,beta_kde_cent_odor[inds,:].T,color='grey');\n",
    "ax[1][1].set_title('beta')\n",
    "\n",
    "ax[1][2].plot(x,lowgamma_kde_cent_odor[inds,:].T,color='grey');\n",
    "ax[1][2].set_title('lowgamma')\n",
    "\n",
    "ax[1][3].plot(x,highgamma_kde_cent_odor[inds,:].T,color='indigo');\n",
    "ax[1][3].set_title('highgamma')\n",
    "\n",
    "#CLUST 2\n",
    "\n",
    "rhythm = 'highgamma'\n",
    "subclust = cluster_id_df[cluster_id_df['highgamma_clust_id'] == 2]\n",
    "inds = subclust['spktrn_ind_labels'].values\n",
    "ax[2][0].plot(x,theta_kde_cent_odor[inds,:].T,color='grey');\n",
    "ax[2][0].set_title('theta')\n",
    "\n",
    "ax[2][1].plot(x,beta_kde_cent_odor[inds,:].T,color='grey');\n",
    "ax[2][1].set_title('beta')\n",
    "\n",
    "ax[2][2].plot(x,lowgamma_kde_cent_odor[inds,:].T,color='grey');\n",
    "ax[2][2].set_title('lowgamma')\n",
    "\n",
    "ax[2][3].plot(x,highgamma_kde_cent_odor[inds,:].T,color='thistle');\n",
    "ax[2][3].set_title('highgamma')\n",
    "\n",
    "\n",
    "for ax in ax.flatten():\n",
    "    ax.set_ylim(-0.045, .045)\n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f0543d",
   "metadata": {},
   "source": [
    "##### find the fraction of spike trains in each high gamma cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b7f8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CLUST 0\n",
    "rhythm = 'highgamma'\n",
    "subclust = cluster_id_df[cluster_id_df['highgamma_clust_id'] == 0]\n",
    "inds = subclust['spktrn_ind_labels'].values\n",
    "\n",
    "clust0_number = len(inds)\n",
    "clust0_fraction = clust0_number/n_spktrns\n",
    "\n",
    "## CLUST 1\n",
    "\n",
    "rhythm = 'highgamma'\n",
    "subclust = cluster_id_df[cluster_id_df['highgamma_clust_id'] == 1]\n",
    "inds = subclust['spktrn_ind_labels'].values\n",
    "\n",
    "clust1_number = len(inds)\n",
    "clust1_fraction = clust1_number/n_spktrns\n",
    "#CLUST 2\n",
    "\n",
    "rhythm = 'highgamma'\n",
    "subclust = cluster_id_df[cluster_id_df['highgamma_clust_id'] == 2]\n",
    "inds = subclust['spktrn_ind_labels'].values\n",
    "\n",
    "clust2_number = len(inds)\n",
    "clust2_fraction = clust2_number/n_spktrns\n",
    "\n",
    "print('clust0: ', clust0_fraction, 'n= ', clust0_number,\n",
    "      '\\nclust1: ', clust1_fraction, 'n= ', clust1_number,\n",
    "      '\\nclust2: ' , clust2_fraction,'n= ', clust2_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2416f7",
   "metadata": {},
   "source": [
    "### now, figure out how many interneurons changed cluster id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91802e62",
   "metadata": {},
   "source": [
    "##### theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b214df0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cluster_id_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/95/7z0h1t9s5tx7km1h1t7t08kw0000gn/T/ipykernel_2826/3982579588.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcell_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster_id_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cell_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mn_cells_clust_change\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtheta_shifting_cells\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mwhich_theta_shifts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cluster_id_df' is not defined"
     ]
    }
   ],
   "source": [
    "cell_labels = list(set(cluster_id_df['cell_id']))\n",
    "\n",
    "n_cells_clust_change = 0\n",
    "theta_shifting_cells = []\n",
    "which_theta_shifts = []\n",
    "for cell_id in cell_labels:\n",
    "    \n",
    "    subclust = cluster_id_df[cluster_id_df['cell_id']==cell_id]\n",
    "    \n",
    "    unique_cluster_ids = set(subclust['theta_clust_id'].values)\n",
    "    \n",
    "    if len(unique_cluster_ids) > 1:\n",
    "        n_cells_clust_change += 1\n",
    "        theta_shifting_cells.append(cell_id)\n",
    "        which_theta_shifts.append(unique_cluster_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0789e2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(i,j) for i,j in zip(theta_shifting_cells,which_theta_shifts)]\n",
    "print(len(theta_shifting_cells),len(cell_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f7a475",
   "metadata": {},
   "source": [
    "##### low gamma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d00b342",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_labels = list(set(cluster_id_df['cell_id']))\n",
    "\n",
    "n_cells_clust_change = 0\n",
    "lowgamma_shifting_cells = []\n",
    "which_lowgamma_shifts = []\n",
    "for cell_id in cell_labels:\n",
    "    \n",
    "    subclust = cluster_id_df[cluster_id_df['cell_id']==cell_id]\n",
    "    \n",
    "    unique_cluster_ids = set(subclust['lowgamma_clust_id'].values)\n",
    "    \n",
    "    if len(unique_cluster_ids) > 1:\n",
    "        n_cells_clust_change += 1\n",
    "        lowgamma_shifting_cells.append(cell_id)\n",
    "        which_lowgamma_shifts.append(unique_cluster_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be0f9836",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lowgamma_shifting_cells' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/95/7z0h1t9s5tx7km1h1t7t08kw0000gn/T/ipykernel_2826/876416689.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlowgamma_shifting_cells\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwhich_lowgamma_shifts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lowgamma_shifting_cells' is not defined"
     ]
    }
   ],
   "source": [
    "[(i,j) for i,j in zip(lowgamma_shifting_cells,which_lowgamma_shifts)]\n",
    "print(len(lowgamma_shifting_cells), len(cell_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302b9ddf",
   "metadata": {},
   "source": [
    "##### high gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ceae51",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_labels = list(set(cluster_id_df['cell_id']))\n",
    "\n",
    "n_cells_clust_change = 0\n",
    "highgamma_shifting_cells = []\n",
    "which_highgamma_shifts = []\n",
    "for cell_id in cell_labels:\n",
    "    \n",
    "    subclust = cluster_id_df[cluster_id_df['cell_id']==cell_id]\n",
    "    \n",
    "    unique_cluster_ids = set(subclust['highgamma_clust_id'].values)\n",
    "    \n",
    "    if len(unique_cluster_ids) > 1:\n",
    "        n_cells_clust_change += 1\n",
    "        highgamma_shifting_cells.append(cell_id)\n",
    "        which_highgamma_shifts.append(unique_cluster_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be20a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(i,j) for i,j in zip(highgamma_shifting_cells,which_highgamma_shifts)]\n",
    "print(len(highgamma_shifting_cells), len(cell_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d32bbe",
   "metadata": {},
   "source": [
    "## are there systematic relationships across rhythmic circuits? \n",
    "here, you'll set yourself up to compute conditional probabilities of cross-rhythmic cluster membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a21256",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_spktrains = cluster_id_df.groupby(['theta_clust_id','spktrn_ind_labels']).count().index\n",
    "theta_clust0_spktrns = []\n",
    "theta_clust1_spktrns = []\n",
    "theta_clust2_spktrns = []\n",
    "theta_clust3_spktrns = []\n",
    "for s in theta_spktrains: \n",
    "    \n",
    "    clust = s[0]\n",
    "    spktrn = s[1]\n",
    "    \n",
    "    if clust == 0: \n",
    "        \n",
    "        theta_clust0_spktrns.append(spktrn)\n",
    "        \n",
    "    if clust == 1: \n",
    "        \n",
    "        theta_clust1_spktrns.append(spktrn)\n",
    "        \n",
    "    if clust == 2 :\n",
    "        \n",
    "        theta_clust2_spktrns.append(spktrn)\n",
    "        \n",
    "    if clust == 3 :\n",
    "        \n",
    "        theta_clust3_spktrns.append(spktrn)\n",
    "        \n",
    "        \n",
    "lowgamma_spktrains = cluster_id_df.groupby(['lowgamma_clust_id','spktrn_ind_labels']).count().index\n",
    "lowgamma_clust0_spktrns = []\n",
    "lowgamma_clust1_spktrns = []\n",
    "lowgamma_clust2_spktrns = []\n",
    "lowgamma_clust3_spktrns = []\n",
    "for s in lowgamma_spktrains: \n",
    "    \n",
    "    clust = s[0]\n",
    "    spktrn = s[1]\n",
    "    \n",
    "    if clust == 0: \n",
    "        \n",
    "        lowgamma_clust0_spktrns.append(spktrn)\n",
    "        \n",
    "    if clust == 1: \n",
    "        \n",
    "        lowgamma_clust1_spktrns.append(spktrn)\n",
    "        \n",
    "    if clust == 2 :\n",
    "        \n",
    "        lowgamma_clust2_spktrns.append(spktrn)\n",
    "        \n",
    "    if clust == 3 :\n",
    "        \n",
    "        lowgamma_clust3_spktrns.append(spktrn)\n",
    "    \n",
    "    \n",
    "highgamma_spktrains = cluster_id_df.groupby(['highgamma_clust_id','spktrn_ind_labels']).count().index\n",
    "highgamma_clust0_spktrns = []\n",
    "highgamma_clust1_spktrns = []\n",
    "highgamma_clust2_spktrns = []\n",
    "for s in highgamma_spktrains: \n",
    "    \n",
    "    clust = s[0]\n",
    "    spktrn = s[1]\n",
    "    \n",
    "    if clust == 0: \n",
    "        \n",
    "        highgamma_clust0_spktrns.append(spktrn)\n",
    "        \n",
    "    if clust == 1: \n",
    "        \n",
    "        highgamma_clust1_spktrns.append(spktrn)\n",
    "        \n",
    "    if clust == 2 :\n",
    "        \n",
    "        highgamma_clust2_spktrns.append(spktrn)\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b358ef9",
   "metadata": {},
   "source": [
    "below you'll actually compute the conditional probs, and then check that the probabilities work out to one per row of theta cluster identity, collapsing across high gamma or low gamma cluster identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8979548a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trueL0T0 = len(set(theta_clust0_spktrns) & set(lowgamma_clust0_spktrns)) / len(set(theta_clust0_spktrns))\n",
    "trueL1T0 = len(set(theta_clust0_spktrns) & set(lowgamma_clust1_spktrns)) / len(set(theta_clust0_spktrns))\n",
    "trueL2T0 = len(set(theta_clust0_spktrns) & set(lowgamma_clust2_spktrns)) / len(set(theta_clust0_spktrns))\n",
    "trueL3T0 = len(set(theta_clust0_spktrns) & set(lowgamma_clust3_spktrns)) / len(set(theta_clust0_spktrns))\n",
    "\n",
    "trueL0T1 = len(set(theta_clust1_spktrns) & set(lowgamma_clust0_spktrns)) / len(set(theta_clust1_spktrns))\n",
    "trueL1T1 = len(set(theta_clust1_spktrns) & set(lowgamma_clust1_spktrns)) / len(set(theta_clust1_spktrns))\n",
    "trueL2T1 = len(set(theta_clust1_spktrns) & set(lowgamma_clust2_spktrns)) / len(set(theta_clust1_spktrns))\n",
    "trueL3T1 = len(set(theta_clust1_spktrns) & set(lowgamma_clust3_spktrns)) / len(set(theta_clust1_spktrns))\n",
    "\n",
    "trueL0T2 = len(set(theta_clust2_spktrns) & set(lowgamma_clust0_spktrns)) / len(set(theta_clust2_spktrns))\n",
    "trueL1T2 = len(set(theta_clust2_spktrns) & set(lowgamma_clust1_spktrns)) / len(set(theta_clust2_spktrns))\n",
    "trueL2T2 = len(set(theta_clust2_spktrns) & set(lowgamma_clust2_spktrns)) / len(set(theta_clust2_spktrns))\n",
    "trueL3T2 = len(set(theta_clust2_spktrns) & set(lowgamma_clust3_spktrns)) / len(set(theta_clust2_spktrns))\n",
    "\n",
    "trueL0T3 = len(set(theta_clust3_spktrns) & set(lowgamma_clust0_spktrns)) / len(set(theta_clust3_spktrns))\n",
    "trueL1T3 = len(set(theta_clust3_spktrns) & set(lowgamma_clust1_spktrns)) / len(set(theta_clust3_spktrns))\n",
    "trueL2T3 = len(set(theta_clust3_spktrns) & set(lowgamma_clust2_spktrns)) / len(set(theta_clust3_spktrns))\n",
    "trueL3T3 = len(set(theta_clust3_spktrns) & set(lowgamma_clust3_spktrns)) / len(set(theta_clust3_spktrns))\n",
    "\n",
    "print(trueL0T0 + trueL1T0 + trueL2T0 + trueL3T0, trueL0T1 + trueL1T1 + trueL2T1 + trueL3T1, trueL0T2 + trueL1T2 + trueL2T2 + trueL3T2, trueL0T3 + trueL1T3 + trueL2T3 + trueL3T3)\n",
    "\n",
    "\n",
    "\n",
    "trueH0T0 = len(set(theta_clust0_spktrns) & set(highgamma_clust0_spktrns)) / len(set(theta_clust0_spktrns))\n",
    "trueH1T0 = len(set(theta_clust0_spktrns) & set(highgamma_clust1_spktrns)) / len(set(theta_clust0_spktrns))\n",
    "trueH2T0 = len(set(theta_clust0_spktrns) & set(highgamma_clust2_spktrns)) / len(set(theta_clust0_spktrns))\n",
    "\n",
    "trueH0T1 = len(set(theta_clust1_spktrns) & set(highgamma_clust0_spktrns)) / len(set(theta_clust1_spktrns))\n",
    "trueH1T1 = len(set(theta_clust1_spktrns) & set(highgamma_clust1_spktrns)) / len(set(theta_clust1_spktrns))\n",
    "trueH2T1 = len(set(theta_clust1_spktrns) & set(highgamma_clust2_spktrns)) / len(set(theta_clust1_spktrns))\n",
    "\n",
    "trueH0T2 = len(set(theta_clust2_spktrns) & set(highgamma_clust0_spktrns)) / len(set(theta_clust2_spktrns))\n",
    "trueH1T2 = len(set(theta_clust2_spktrns) & set(highgamma_clust1_spktrns)) / len(set(theta_clust2_spktrns))\n",
    "trueH2T2 = len(set(theta_clust2_spktrns) & set(highgamma_clust2_spktrns)) / len(set(theta_clust2_spktrns))\n",
    "\n",
    "trueH0T3 = len(set(theta_clust3_spktrns) & set(highgamma_clust0_spktrns)) / len(set(theta_clust3_spktrns))\n",
    "trueH1T3 = len(set(theta_clust3_spktrns) & set(highgamma_clust1_spktrns)) / len(set(theta_clust3_spktrns))\n",
    "trueH2T3 = len(set(theta_clust3_spktrns) & set(highgamma_clust2_spktrns)) / len(set(theta_clust3_spktrns))\n",
    "\n",
    "\n",
    "print(trueH0T0 + trueH1T0 + trueH2T0, trueH0T1 + trueH1T1 + trueH2T1, trueH0T2 + trueH1T2 + trueH2T2, trueH0T3 + trueH1T3 + trueH2T3)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dbd7d8",
   "metadata": {},
   "source": [
    "set these data up nicely to plot using seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eeca3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "LgivenT = {'Tdesc': [trueL0T0,trueL1T0,trueL2T0,trueL3T0],\n",
    "           'Tasc': [trueL0T1,trueL1T1,trueL2T1,trueL3T1],\n",
    "           'Tearlydesc': [trueL0T2,trueL1T2,trueL2T2,trueL3T2],\n",
    "           'Tuni': [trueL0T3,trueL1T3,trueL2T3,trueL3T3]\n",
    "          }\n",
    "LgivenT_df = pd.DataFrame(LgivenT)\n",
    "\n",
    "T = pd.Series(['Learlydesc','Llatedesc','Lpeak','Luni'])\n",
    "LgivenT_df = LgivenT_df.set_index(T)\n",
    "\n",
    "HgivenT = {'Tdesc': [trueH0T0,trueH1T0,trueH2T0],\n",
    "           'Tasc': [trueH0T1,trueH1T1,trueH2T1],\n",
    "           'Tearlydesc': [trueH0T2,trueH1T2,trueH2T2],\n",
    "           'Tuni': [trueH0T3,trueH1T3,trueH2T3]\n",
    "          }\n",
    "HgivenT_df = pd.DataFrame(HgivenT)\n",
    "\n",
    "T = pd.Series(['Hdesc','Hasc','Huni'])\n",
    "HgivenT_df = HgivenT_df.set_index(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3d7c06",
   "metadata": {},
   "source": [
    "### Figure 2C (left columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92f4968",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=2)\n",
    "fig,ax = plt.subplots(1,2,figsize=(16,6))\n",
    "\n",
    "\n",
    "g = sns.heatmap(data=LgivenT_df,\n",
    "                vmin=0,\n",
    "                vmax=1,\n",
    "                annot=True,\n",
    "                annot_kws={\"size\": 16},\n",
    "                ax=ax[0]\n",
    "               ).set_title('lowgamma clust id given theta clust id')\n",
    "\n",
    "\n",
    "\n",
    "g = sns.heatmap(data=HgivenT_df,\n",
    "                vmin=0,\n",
    "                vmax=1,\n",
    "                annot=True,\n",
    "                annot_kws={\"size\": 16},\n",
    "                ax=ax[1]\n",
    "               ).set_title('highgamma clust id given theta clust id')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf95a29",
   "metadata": {},
   "source": [
    "Now, get the joint probabilities of low gamma and high gamma cluster membership--you will work to find the intersection of venn diagrams of low gamma and high gamma cluster membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f076584a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trueH0L0 = len(set(highgamma_clust0_spktrns) & set(lowgamma_clust0_spktrns)) / ((len(highgamma_clust0_spktrns) + len(lowgamma_clust0_spktrns)) - len(set(highgamma_clust0_spktrns) & set(lowgamma_clust0_spktrns)))\n",
    "trueH0L1 = len(set(highgamma_clust0_spktrns) & set(lowgamma_clust1_spktrns)) / ((len(highgamma_clust0_spktrns) + len(lowgamma_clust1_spktrns)) - len(set(highgamma_clust0_spktrns) & set(lowgamma_clust1_spktrns)))\n",
    "trueH0L2 = len(set(highgamma_clust0_spktrns) & set(lowgamma_clust2_spktrns)) / ((len(highgamma_clust0_spktrns) + len(lowgamma_clust2_spktrns)) - len(set(highgamma_clust0_spktrns) & set(lowgamma_clust2_spktrns)))\n",
    "trueH0L3 = len(set(highgamma_clust0_spktrns) & set(lowgamma_clust3_spktrns)) / ((len(highgamma_clust0_spktrns) + len(lowgamma_clust3_spktrns)) - len(set(highgamma_clust0_spktrns) & set(lowgamma_clust3_spktrns)))\n",
    "\n",
    "trueH1L0 = len(set(highgamma_clust1_spktrns) & set(lowgamma_clust0_spktrns)) / ((len(highgamma_clust1_spktrns) + len(lowgamma_clust0_spktrns)) - len(set(highgamma_clust1_spktrns) & set(lowgamma_clust0_spktrns)))\n",
    "trueH1L1 = len(set(highgamma_clust1_spktrns) & set(lowgamma_clust1_spktrns)) / ((len(highgamma_clust1_spktrns) + len(lowgamma_clust1_spktrns)) - len(set(highgamma_clust1_spktrns) & set(lowgamma_clust1_spktrns)))\n",
    "trueH1L2 = len(set(highgamma_clust1_spktrns) & set(lowgamma_clust2_spktrns)) / ((len(highgamma_clust1_spktrns) + len(lowgamma_clust2_spktrns)) - len(set(highgamma_clust1_spktrns) & set(lowgamma_clust2_spktrns)))\n",
    "trueH1L3 = len(set(highgamma_clust1_spktrns) & set(lowgamma_clust3_spktrns)) / ((len(highgamma_clust1_spktrns) + len(lowgamma_clust3_spktrns)) - len(set(highgamma_clust1_spktrns) & set(lowgamma_clust3_spktrns)))\n",
    "\n",
    "trueH2L0 = len(set(highgamma_clust2_spktrns) & set(lowgamma_clust0_spktrns)) / ((len(highgamma_clust2_spktrns) + len(lowgamma_clust0_spktrns)) - len(set(highgamma_clust2_spktrns) & set(lowgamma_clust0_spktrns)))\n",
    "trueH2L1 = len(set(highgamma_clust2_spktrns) & set(lowgamma_clust1_spktrns)) / ((len(highgamma_clust2_spktrns) + len(lowgamma_clust1_spktrns)) - len(set(highgamma_clust2_spktrns) & set(lowgamma_clust1_spktrns)))\n",
    "trueH2L2 = len(set(highgamma_clust2_spktrns) & set(lowgamma_clust2_spktrns)) / ((len(highgamma_clust2_spktrns) + len(lowgamma_clust2_spktrns)) - len(set(highgamma_clust2_spktrns) & set(lowgamma_clust2_spktrns)))\n",
    "trueH2L3 = len(set(highgamma_clust2_spktrns) & set(lowgamma_clust3_spktrns)) / ((len(highgamma_clust2_spktrns) + len(lowgamma_clust3_spktrns)) - len(set(highgamma_clust2_spktrns) & set(lowgamma_clust3_spktrns)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d19c47",
   "metadata": {},
   "source": [
    "set it up nicely for seaborn plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a905f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "HandL = {'H0andL': [trueH0L0,trueH0L1,trueH0L2,trueH0L3],\n",
    "         'H1andL': [trueH1L0,trueH1L1,trueH1L2,trueH1L3],\n",
    "         'H2andL': [trueH2L0,trueH2L1,trueH2L2,trueH2L3]\n",
    "          }\n",
    "HandL_df = pd.DataFrame(HandL)\n",
    "\n",
    "L = pd.Series(['Learlydesc','Learlyasc','Lpeak','Luni'])\n",
    "HandL_df = HandL_df.set_index(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b53070",
   "metadata": {},
   "source": [
    "### Figure 2D (left columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5e17ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5)\n",
    "fig,ax = plt.subplots(figsize=(8,5))\n",
    "\n",
    "\n",
    "g = sns.heatmap(data=HandL_df,\n",
    "                vmin=0,\n",
    "                vmax=1,\n",
    "                annot=True,\n",
    "                annot_kws={\"size\": 16},\n",
    "                ax=ax).set_title('joint probs \\n lowgamma clust id and high gamma clust id')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f12406",
   "metadata": {},
   "source": [
    "## permutation tests: what would the conditional & joint probabilities have looked like by chance? \n",
    "here, try out shuffling the spike times within a theta phase bin relative to the lfp, and see whether you can still get this distribution of conditional probabilities by chance -- importantly, you don't have to fit new models: the important thing is to get the shuffled spike-train's rayleigh statistics and circular mean preference relative to the high frequency rhythms. Since you won't have disturbed the theta phase relationship, the columns of the conditional probs heatmaps above stay the same, it's just that the entries should change if those above are unique, and not attainable by chance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c0262e",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = 'python_spkphase_odorsamp/'\n",
    "files = os.listdir(datapath)\n",
    "files = [f for f in files if not f.startswith('.')]\n",
    "\n",
    "fs = 1000 \n",
    "nperms = 20\n",
    "\n",
    "\n",
    "gather_dfs = []\n",
    "\n",
    "savedir = 'perm_spikes_byclustbin_odorsamp/'\n",
    "for file in tqdm(files,position=0,leave=True,colour='cornflowerblue'): \n",
    "    \n",
    "    df = pd.read_csv(os.path.join(datapath,file))\n",
    "    odorsamp_df = df[df['trial_segment']=='dur']\n",
    "    \n",
    "    ratsession = file.split('_')[0] + '_' + file.split('_')[1]\n",
    "    \n",
    "    #find all neurons in the dataset\n",
    "    neuron_expression = 'TETSPK'\n",
    "    neuron_cols = get_neuron_cols(odorsamp_df,neuron_expression)\n",
    "    \n",
    "    for neuron in neuron_cols: \n",
    "        \n",
    "        gather_permspikes = pd.DataFrame()\n",
    "        gather_cycles = pd.DataFrame()\n",
    "        gather_meta = pd.DataFrame()\n",
    "        \n",
    "        #find the corresponding lfp\n",
    "        allow_wire = get_allowable_lfp_wires(odorsamp_df,'K')\n",
    "        \n",
    "        lfp_expression = \"TETFP\"+allow_wire[0]+\"\\Z|TETFP\"+allow_wire[1]+\"\\Z|TETFP\"+allow_wire[2]+\"\\Z|TETFP\"+allow_wire[3]+\"\\Z\"\n",
    "        lfp_cols = get_lfp_cols(odorsamp_df,lfp_expression)\n",
    "        \n",
    "        for lfpname in lfp_cols: \n",
    "\n",
    "            #now compute the phase estimates for these filtered columns\n",
    "            analytic = hilbert(odorsamp_df[lfpname+'filt_theta'].values)\n",
    "            phase = np.arctan2(odorsamp_df[lfpname+'filt_theta'].values,analytic.imag)\n",
    "            \n",
    "            odorsamp_df[lfpname+'phase_theta'] = phase\n",
    "\n",
    "            #add a column of labels that marks which theta phase bin (as defined by the cluster edges above)\n",
    "            #describes each lfp cycle\n",
    "            theta_phase_edges = [-np.pi,-3,-1,1.5,np.pi]\n",
    "            theta_bin_labels = [2,0,1,2] #cluster identities as arbitrarily defined above\n",
    "\n",
    "            odorsamp_df[lfpname+'theta_clust_bins'] = pd.cut(phase,\n",
    "                                                             bins = theta_phase_edges,\n",
    "                                                             labels = theta_bin_labels,\n",
    "                                                             ordered=False,\n",
    "                                                             right=False,\n",
    "                                                             include_lowest=True\n",
    "                                                            )\n",
    "\n",
    "            conditions = list(set(odorsamp_df['odor_labels']))\n",
    "\n",
    "            for condition in conditions: \n",
    "\n",
    "                subcondition = odorsamp_df[odorsamp_df['odor_labels']==condition]\n",
    "\n",
    "                acc = subcondition['accuracy'].iloc[0]\n",
    "                if acc >= .75: \n",
    "                    \n",
    "                    trial_labels = list(set(subcondition['trial_labels']))\n",
    "                    \n",
    "                    if len(trial_labels) >= 4: \n",
    "                    \n",
    "                        for trial in trial_labels: \n",
    "\n",
    "                            subtrial = subcondition[subcondition['trial_labels']==trial]\n",
    "\n",
    "                            #label all the phase cycles so you can iterate through them\n",
    "\n",
    "                            filtcol = lfpname+'filt_theta'\n",
    "                            subtrial = label_phase_cycles(subtrial,filtcol,fs,trial)\n",
    "\n",
    "                            cycle_labels = list(set(subtrial['cycle_labels']))\n",
    "\n",
    "                            for cycle in cycle_labels: \n",
    "\n",
    "                                subcycle = subtrial[subtrial['cycle_labels']==cycle]\n",
    "\n",
    "                                phase_bin_labels = list(set(subcycle[lfpname+'theta_clust_bins']))\n",
    "\n",
    "                                for pbl in phase_bin_labels: \n",
    "\n",
    "                                    subbin = subcycle[subcycle[lfpname+'theta_clust_bins']==pbl]\n",
    "\n",
    "                                    pos = subbin['pos_labels'].iloc[0]\n",
    "\n",
    "                                    nsamps = subbin.shape[0]\n",
    "\n",
    "                                    gather_binspikes = pd.DataFrame()\n",
    "                                    \n",
    "                                    for perm in range(nperms): \n",
    "\n",
    "                                        index_range = subbin.index\n",
    "                                        new_sequence = np.random.permutation(index_range)\n",
    "                                        spike_shuffle = subbin.reindex(new_sequence)\n",
    "\n",
    "                                        #then set up a dataframe of shuffled spike times\n",
    "                                        #within theta phase bin\n",
    "\n",
    "                                        gather_binspikes['perm'+str(perm)+'_'+neuron] = spike_shuffle[neuron].values\n",
    "                                        permcols = [p for p in gather_binspikes.columns if p.startswith('perm')]\n",
    "\n",
    "\n",
    "                                        mini_meta = {'ratsession_id': np.repeat(ratsession,nsamps),\n",
    "                                                     'accuracy': np.repeat(acc,nsamps),\n",
    "                                                     'odor_labels': np.repeat(condition,nsamps),\n",
    "                                                     'pos_labels': np.repeat(pos,nsamps),\n",
    "                                                     'trial_labels': np.repeat(trial,nsamps),\n",
    "                                                     lfpname: subbin[lfpname].values,\n",
    "                                                     lfpname+'filt_theta': subbin[lfpname+'filt_theta'].values,\n",
    "                                                     lfpname+'filt_lowgamma': subbin[lfpname+'filt_lowgamma'].values,\n",
    "                                                     lfpname+'filt_highgamma': subbin[lfpname+'filt_highgamma'].values,\n",
    "                                                     neuron: subbin[neuron].values,\n",
    "                                                     'cycle_labels': np.repeat(cycle,nsamps),\n",
    "                                                     lfpname+'theta_clust_bins': subbin[lfpname+'theta_clust_bins'].values\n",
    "                                                    }\n",
    "\n",
    "                                    gather_cycles = pd.concat([gather_cycles,gather_binspikes],\n",
    "                                                              ignore_index=True\n",
    "                                                             )\n",
    "                                    gather_meta = pd.concat([gather_meta,pd.DataFrame(mini_meta)],\n",
    "                                                            ignore_index=True\n",
    "                                                           )\n",
    "\n",
    "\n",
    "            gather_permspikes = pd.concat([gather_meta,gather_cycles[permcols]],axis=1)\n",
    "            filename = ratsession + '_' + lfpname + '_' + neuron + 'permspikes.csv'\n",
    "            if not os.path.exists(savedir): \n",
    "                os.makedirs(savedir)\n",
    "\n",
    "            gather_permspikes.to_csv(os.path.join(savedir,filename))\n",
    "\n",
    "                                \n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c29099",
   "metadata": {},
   "source": [
    "With this code, you end up saving all permuted datasets per session, per neuron/LFP combination."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b16ee5",
   "metadata": {},
   "source": [
    "Now, re-create the conditional probabilities of cluster membership given theta cluster membership, but with the permuted spike phase distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401144e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "permpath = 'perm_spikes_byclustbin_odorsamp/'\n",
    "permfiles = os.listdir(permpath)\n",
    "permfiles = [f for f in permfiles if not f.startswith('.')]\n",
    "\n",
    "nsplits = 7 #for model fitting\n",
    "    \n",
    "rhythms = ['theta','lowgamma','highgamma']\n",
    "\n",
    "gather_dfs = pd.DataFrame()\n",
    "for permfile in tqdm(permfiles,position=0,leave=True,colour='cornflowerblue'): \n",
    "    \n",
    "    permdf = pd.read_csv(os.path.join(permpath,permfile))\n",
    "    permcols = [p for p in permdf.columns if p.startswith('perm')]\n",
    "    \n",
    "    unitwire = permfile.split('perm')[0].split('TETSPK')[1][:2] #grab just the wire number\n",
    "    lfpcol = [fp for fp in permdf.columns if fp.endswith(unitwire)]\n",
    "    counter = 1 #in case the lfpcol is empty because the lfp corresponds to a different wire of the tetrode\n",
    "    while len(lfpcol) == 0: \n",
    "        lfpcol = [fp for fp in permdf.columns if fp.endswith(str(int(unitwire)+counter))]\n",
    "        counter+=1\n",
    "    lfpcol = lfpcol[0]\n",
    "    \n",
    "    ratsession = permfile.split('_')[0] + '_' + permfile.split('_')[1]\n",
    "    \n",
    "    neuron = permfile.split('_')[3].split('perm')[0]\n",
    "    \n",
    "    for permcol in permcols: \n",
    "        \n",
    "        subperm = permdf[['odor_labels',\n",
    "                          'accuracy',\n",
    "                          lfpcol+'filt_theta',\n",
    "                          lfpcol+'filt_lowgamma',\n",
    "                          lfpcol+'filt_highgamma',\n",
    "                          permcol]]\n",
    "        \n",
    "        condition_labels = list(set(subperm['odor_labels']))\n",
    "        \n",
    "        for condition in condition_labels: \n",
    "            \n",
    "            subcond = subperm[subperm['odor_labels']==condition]\n",
    "\n",
    "            df_for_ray = pd.DataFrame()\n",
    "            \n",
    "            acc = subcond['accuracy'].iloc[0]\n",
    "            if (acc >= 0.75) & (subcond[permcol].sum() > nsplits): \n",
    "        \n",
    "                for rhythm in rhythms: \n",
    "                \n",
    "                    #take the phase estimates of the filtered lfp\n",
    "                    filtered = subcond[lfpcol+'filt_'+rhythm].values\n",
    "                    analytic = hilbert(filtered)\n",
    "                    phases = np.arctan2(filtered, analytic.imag)\n",
    "\n",
    "                    spikes = subcond[permcol].values\n",
    "\n",
    "                    #get the spike-phase distribution\n",
    "                    phi_when_sp = []\n",
    "                    for s,p in zip(spikes,phases):\n",
    "                        if s==1: \n",
    "                            phi_when_sp.append(p)\n",
    "\n",
    "                    #get its rayleigh & circmean\n",
    "                    df_for_ray['spikes'] = spikes\n",
    "                    df_for_ray[rhythm+'_phases'] = phases\n",
    "                    ray = rayleigh_pr(df_for_ray, rhythm)\n",
    "\n",
    "                    #put this all in a data frame where all neurons's perm data is together\n",
    "        \n",
    "                    meta = {'ratsession_id': ratsession,\n",
    "                            'neuron': neuron,\n",
    "                            'permutation': permcol,\n",
    "                            'odor_labels': [condition],\n",
    "                           }\n",
    "                    metaray = pd.concat([pd.DataFrame(meta),ray],axis=1)\n",
    "                    gather_dfs = pd.concat([gather_dfs, metaray])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a2446b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gather_dfs['cell_id'] = gather_dfs['ratsession_id'] + '_' + gather_dfs['neuron']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9af6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "kde_odor['odor_labels'] = kde_odor['condition_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dc791b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_labels = list(set(gather_dfs['cell_id']))\n",
    "\n",
    "gather_permdfs = []\n",
    "for cell_id in tqdm(cell_labels,position=0,colour='cornflowerblue'): \n",
    "    \n",
    "    subcell = gather_dfs[gather_dfs['cell_id']==cell_id]\n",
    "    subkde = kde_odor[kde_odor['cell_id']==cell_id]\n",
    "    \n",
    "    odor_labels = list(set(subcell['odor_labels']))\n",
    "    for odor in odor_labels: \n",
    "        \n",
    "        subodor = subcell[subcell['odor_labels']==odor]\n",
    "        subko = subkde[subkde['odor_labels']==odor]\n",
    "        \n",
    "        spktrn_ind = list(set(subko['spktrn_ind_labels']))\n",
    "        \n",
    "        if len(spktrn_ind) == 1:\n",
    "        \n",
    "            subodor['spktrn_ind_labels'] = np.repeat(spktrn_ind,subodor.shape[0])\n",
    "            \n",
    "        else: \n",
    "            \n",
    "            print('more than one spiketrain label found')\n",
    "            \n",
    "        gather_permdfs.append(subodor)\n",
    "        \n",
    "gather_permdfs = pd.concat(gather_permdfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57775fb1",
   "metadata": {},
   "source": [
    "Ok, now apply the clustering scheme for each rhythm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4425068d",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "\n",
    "gather_dfs['significant'] = [1 if (i < alpha) else 0 for i in gather_dfs['pval'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d55112",
   "metadata": {},
   "outputs": [],
   "source": [
    "#theta\n",
    "phase_thresh02 = -3\n",
    "phase_thresh0 = -1\n",
    "phase_thresh2 = 1.5\n",
    "\n",
    "\n",
    "permsubtheta_sig = gather_dfs[(gather_dfs['rhythm'] == 'theta') & (gather_dfs['significant'] == 1)]\n",
    "permsubtheta_nosig = gather_dfs[(gather_dfs['rhythm'] == 'theta') & (gather_dfs['significant'] == 0)]\n",
    "\n",
    "permcluster0 = permsubtheta_sig[(permsubtheta_sig['circmean'] > phase_thresh02) & (permsubtheta_sig['circmean'] < phase_thresh0)].reset_index()\n",
    "permcluster1 = permsubtheta_sig[(permsubtheta_sig['circmean'] >= phase_thresh0) & (permsubtheta_sig['circmean'] <= phase_thresh2)].reset_index()\n",
    "permcluster2a = permsubtheta_sig[(permsubtheta_sig['circmean'] > phase_thresh2)].reset_index()\n",
    "permcluster2b = permsubtheta_sig[(permsubtheta_sig['circmean'] <= phase_thresh02)].reset_index()\n",
    "permcluster2 = pd.concat([permcluster2a,permcluster2b])\n",
    "permcluster3 = permsubtheta_nosig.reset_index()\n",
    "\n",
    "permcluster0['theta_clust_id'] = np.repeat(0,permcluster0.shape[0])\n",
    "permcluster1['theta_clust_id'] = np.repeat(1,permcluster1.shape[0])\n",
    "permcluster2['theta_clust_id'] = np.repeat(2,permcluster2.shape[0])\n",
    "permcluster3['theta_clust_id'] = np.repeat(3,permcluster3.shape[0])\n",
    "\n",
    "permtheta_cluster_id_df = pd.concat([permcluster0,permcluster1,permcluster2,permcluster3])\n",
    "\n",
    "subtheta_clust_df = permtheta_cluster_id_df[['cell_id',\n",
    "                                             'permutation',\n",
    "                                             'odor_labels',\n",
    "                                             'theta_clust_id',\n",
    "                                             'spktrn_ind_labels'\n",
    "                                            ]]\n",
    "\n",
    "#lowgamma\n",
    "\n",
    "permsublowgamma_sig = gather_dfs[(gather_dfs['rhythm'] == 'lowgamma') & (gather_dfs['significant'] == 1)]\n",
    "permsublowgamma_nosig = gather_dfs[(gather_dfs['rhythm'] == 'lowgamma') & (gather_dfs['significant'] == 0)]\n",
    "\n",
    "phase_threshleft = -2\n",
    "phase_threshright = 2\n",
    "phase_threshmidright = 0.4\n",
    "\n",
    "permcluster0a = permsublowgamma_sig[(permsublowgamma_sig['circmean'] < phase_threshleft)].reset_index()\n",
    "permcluster0b = permsublowgamma_sig[(permsublowgamma_sig['circmean'] > phase_threshright)].reset_index()\n",
    "permcluster0 = pd.concat([permcluster0a,permcluster0b])\n",
    "permcluster1 = permsublowgamma_sig[(permsublowgamma_sig['circmean'] >= phase_threshleft) & (permsublowgamma_sig['circmean'] <= phase_threshmidright)].reset_index()\n",
    "permcluster2 = permsublowgamma_sig[(permsublowgamma_sig['circmean'] >= phase_threshmidright) & (permsublowgamma_sig['circmean'] <= phase_threshright)].reset_index()\n",
    "permcluster3 = permsublowgamma_nosig.reset_index()\n",
    "\n",
    "permcluster0['lowgamma_clust_id'] = np.repeat(0,permcluster0.shape[0])\n",
    "permcluster1['lowgamma_clust_id'] = np.repeat(1,permcluster1.shape[0])\n",
    "permcluster2['lowgamma_clust_id'] = np.repeat(2,permcluster2.shape[0])\n",
    "permcluster3['lowgamma_clust_id'] = np.repeat(3,permcluster3.shape[0])\n",
    "\n",
    "permlowgamma_cluster_id_df = pd.concat([permcluster0,permcluster1,permcluster2,permcluster3])\n",
    "\n",
    "sublowgamma_clust_df = permlowgamma_cluster_id_df[['cell_id',\n",
    "                                                   'permutation',\n",
    "                                                   'odor_labels',\n",
    "                                                   'lowgamma_clust_id',\n",
    "                                                   'spktrn_ind_labels'\n",
    "                                                  ]]\n",
    "\n",
    "\n",
    "#highgamma\n",
    "\n",
    "permsubhighgamma_sig = gather_dfs[(gather_dfs['rhythm'] == 'highgamma') & (gather_dfs['significant'] == 1)]\n",
    "permsubhighgamma_nosig = gather_dfs[(gather_dfs['rhythm'] == 'highgamma') & (gather_dfs['significant'] == 0)]\n",
    "\n",
    "phase_thresh01 = -1.5\n",
    "phase_thresh10 = 1\n",
    "\n",
    "permcluster0a = permsubhighgamma_sig[(permsubhighgamma_sig['circmean'] < phase_thresh01)].reset_index()\n",
    "permcluster0b = permsubhighgamma_sig[(permsubhighgamma_sig['circmean'] > phase_thresh10)].reset_index()\n",
    "permcluster0 = pd.concat([permcluster0a,permcluster0b])\n",
    "permcluster1 = permsubhighgamma_sig[(permsubhighgamma_sig['circmean'] >= phase_thresh01) & (permsubhighgamma_sig['circmean'] <= phase_thresh10)].reset_index()\n",
    "permcluster2 = permsubhighgamma_nosig.reset_index()\n",
    "\n",
    "permcluster0['highgamma_clust_id'] = np.repeat(0,permcluster0.shape[0])\n",
    "permcluster1['highgamma_clust_id'] = np.repeat(1,permcluster1.shape[0])\n",
    "permcluster2['highgamma_clust_id'] = np.repeat(2,permcluster2.shape[0])\n",
    "\n",
    "permhighgamma_cluster_id_df = pd.concat([permcluster0,permcluster1,permcluster2])\n",
    "\n",
    "subhighgamma_clust_df = permhighgamma_cluster_id_df[['cell_id',\n",
    "                                                     'permutation',\n",
    "                                                     'odor_labels',\n",
    "                                                     'highgamma_clust_id',\n",
    "                                                     'spktrn_ind_labels'\n",
    "                                                    ]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8a6947",
   "metadata": {},
   "outputs": [],
   "source": [
    "permlabels = list(set(subtheta_clust_df['permutation']))\n",
    "nperms = 20\n",
    "npermlist = [int(i) for i in np.linspace(0,nperms-1,nperms)]\n",
    "\n",
    "theta_clust0_perms = []\n",
    "theta_clust1_perms = []\n",
    "theta_clust2_perms = []\n",
    "theta_clust3_perms = []\n",
    "\n",
    "for perm in tqdm(npermlist,position=0,colour='cornflowerblue'): \n",
    "    \n",
    "    selectperms = [p for p in permlabels if p.startswith('perm'+str(perm)+'_')]\n",
    "    subperm_theta = subtheta_clust_df[subtheta_clust_df['permutation'].isin(selectperms)]\n",
    "\n",
    "    theta_spktrains = subperm_theta.groupby(['theta_clust_id','spktrn_ind_labels']).count().index\n",
    "    theta_clust0_spktrns = []\n",
    "    theta_clust1_spktrns = []\n",
    "    theta_clust2_spktrns = []\n",
    "    theta_clust3_spktrns = []\n",
    "\n",
    "    for s in theta_spktrains: \n",
    "\n",
    "        clust = s[0]\n",
    "        spktrn = s[1]\n",
    "\n",
    "        if clust == 0: \n",
    "\n",
    "            theta_clust0_spktrns.append(spktrn)\n",
    "\n",
    "        if clust == 1: \n",
    "\n",
    "            theta_clust1_spktrns.append(spktrn)\n",
    "\n",
    "        if clust == 2 :\n",
    "\n",
    "            theta_clust2_spktrns.append(spktrn)\n",
    "\n",
    "        if clust == 3 :\n",
    "\n",
    "            theta_clust3_spktrns.append(spktrn)\n",
    "\n",
    "\n",
    "    theta_clust0_perms.append(pd.DataFrame({'perm': perm,\n",
    "                               'spktrns': theta_clust0_spktrns\n",
    "                              }))\n",
    "    theta_clust1_perms.append(pd.DataFrame({'perm': perm,\n",
    "                               'spktrns': theta_clust1_spktrns\n",
    "                              }))\n",
    "    theta_clust2_perms.append(pd.DataFrame({'perm': perm,\n",
    "                               'spktrns': theta_clust2_spktrns\n",
    "                              }))\n",
    "    theta_clust3_perms.append(pd.DataFrame({'perm': perm,\n",
    "                               'spktrns': theta_clust3_spktrns\n",
    "                              }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f396e262",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_clust0_perms = pd.concat(theta_clust0_perms)\n",
    "theta_clust1_perms = pd.concat(theta_clust1_perms)\n",
    "theta_clust2_perms = pd.concat(theta_clust2_perms)\n",
    "theta_clust3_perms = pd.concat(theta_clust3_perms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49ad671",
   "metadata": {},
   "outputs": [],
   "source": [
    "permlabels = list(set(sublowgamma_clust_df['permutation']))\n",
    "\n",
    "npermlist = [int(i) for i in np.linspace(0,nperms-1,nperms)]\n",
    "\n",
    "lowgamma_clust0_perms = []\n",
    "lowgamma_clust1_perms = []\n",
    "lowgamma_clust2_perms = []\n",
    "lowgamma_clust3_perms = []\n",
    "\n",
    "for perm in tqdm(npermlist,position=0,colour='cornflowerblue'): \n",
    "    \n",
    "    selectperms = [p for p in permlabels if p.startswith('perm'+str(perm)+'_')]\n",
    "    subperm_lowgamma = sublowgamma_clust_df[sublowgamma_clust_df['permutation'].isin(selectperms)]\n",
    "\n",
    "    lowgamma_spktrains = subperm_lowgamma.groupby(['lowgamma_clust_id','spktrn_ind_labels']).count().index\n",
    "    lowgamma_clust0_spktrns = []\n",
    "    lowgamma_clust1_spktrns = []\n",
    "    lowgamma_clust2_spktrns = []\n",
    "    lowgamma_clust3_spktrns = []\n",
    "\n",
    "    for s in lowgamma_spktrains: \n",
    "\n",
    "        clust = s[0]\n",
    "        spktrn = s[1]\n",
    "\n",
    "        if clust == 0: \n",
    "\n",
    "            lowgamma_clust0_spktrns.append(spktrn)\n",
    "\n",
    "        if clust == 1: \n",
    "\n",
    "            lowgamma_clust1_spktrns.append(spktrn)\n",
    "\n",
    "        if clust == 2 :\n",
    "\n",
    "            lowgamma_clust2_spktrns.append(spktrn)\n",
    "\n",
    "        if clust == 3 :\n",
    "\n",
    "            lowgamma_clust3_spktrns.append(spktrn)\n",
    "\n",
    "\n",
    "    lowgamma_clust0_perms.append(pd.DataFrame({'perm': perm,\n",
    "                               'spktrns': lowgamma_clust0_spktrns\n",
    "                              }))\n",
    "    lowgamma_clust1_perms.append(pd.DataFrame({'perm': perm,\n",
    "                               'spktrns': lowgamma_clust1_spktrns\n",
    "                              }))\n",
    "    lowgamma_clust2_perms.append(pd.DataFrame({'perm': perm,\n",
    "                               'spktrns': lowgamma_clust2_spktrns\n",
    "                              }))\n",
    "    lowgamma_clust3_perms.append(pd.DataFrame({'perm': perm,\n",
    "                               'spktrns': lowgamma_clust3_spktrns\n",
    "                              }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3560cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowgamma_clust0_perms = pd.concat(lowgamma_clust0_perms)\n",
    "lowgamma_clust1_perms = pd.concat(lowgamma_clust1_perms)\n",
    "lowgamma_clust2_perms = pd.concat(lowgamma_clust2_perms)\n",
    "lowgamma_clust3_perms = pd.concat(lowgamma_clust3_perms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496b74d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "permlabels = list(set(subhighgamma_clust_df['permutation']))\n",
    "\n",
    "npermlist = [int(i) for i in np.linspace(0,nperms-1,nperms)]\n",
    "\n",
    "highgamma_clust0_perms = []\n",
    "highgamma_clust1_perms = []\n",
    "highgamma_clust2_perms = []\n",
    "\n",
    "for perm in tqdm(npermlist,position=0,colour='cornflowerblue'): \n",
    "    \n",
    "    selectperms = [p for p in permlabels if p.startswith('perm'+str(perm)+'_')]\n",
    "    subperm_highgamma = subhighgamma_clust_df[subhighgamma_clust_df['permutation'].isin(selectperms)]\n",
    "\n",
    "    highgamma_spktrains = subperm_highgamma.groupby(['highgamma_clust_id','spktrn_ind_labels']).count().index\n",
    "    highgamma_clust0_spktrns = []\n",
    "    highgamma_clust1_spktrns = []\n",
    "    highgamma_clust2_spktrns = []\n",
    " \n",
    "\n",
    "    for s in highgamma_spktrains: \n",
    "\n",
    "        clust = s[0]\n",
    "        spktrn = s[1]\n",
    "\n",
    "        if clust == 0: \n",
    "\n",
    "            highgamma_clust0_spktrns.append(spktrn)\n",
    "\n",
    "        if clust == 1: \n",
    "\n",
    "            highgamma_clust1_spktrns.append(spktrn)\n",
    "\n",
    "        if clust == 2 :\n",
    "\n",
    "            highgamma_clust2_spktrns.append(spktrn)\n",
    "\n",
    "\n",
    "    highgamma_clust0_perms.append(pd.DataFrame({'perm': perm,\n",
    "                               'spktrns': highgamma_clust0_spktrns\n",
    "                              }))\n",
    "    highgamma_clust1_perms.append(pd.DataFrame({'perm': perm,\n",
    "                               'spktrns': highgamma_clust1_spktrns\n",
    "                              }))\n",
    "    highgamma_clust2_perms.append(pd.DataFrame({'perm': perm,\n",
    "                               'spktrns': highgamma_clust2_spktrns\n",
    "                              }))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677a7be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "highgamma_clust0_perms = pd.concat(highgamma_clust0_perms)\n",
    "highgamma_clust1_perms = pd.concat(highgamma_clust1_perms)\n",
    "highgamma_clust2_perms = pd.concat(highgamma_clust2_perms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617721e1",
   "metadata": {},
   "source": [
    "Compute all the permuted-data conditional probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22dac33",
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_cond_probs = []\n",
    "for perm in npermlist: \n",
    "    \n",
    "    theta_clust0_spktrns = theta_clust0_perms[theta_clust0_perms['perm']==perm]['spktrns'].values\n",
    "    theta_clust1_spktrns = theta_clust1_perms[theta_clust1_perms['perm']==perm]['spktrns'].values\n",
    "    theta_clust2_spktrns = theta_clust2_perms[theta_clust2_perms['perm']==perm]['spktrns'].values\n",
    "    theta_clust3_spktrns = theta_clust3_perms[theta_clust3_perms['perm']==perm]['spktrns'].values\n",
    "    \n",
    "    lowgamma_clust0_spktrns = lowgamma_clust0_perms[lowgamma_clust0_perms['perm']==perm]['spktrns'].values\n",
    "    lowgamma_clust1_spktrns = lowgamma_clust1_perms[lowgamma_clust1_perms['perm']==perm]['spktrns'].values\n",
    "    lowgamma_clust2_spktrns = lowgamma_clust2_perms[lowgamma_clust2_perms['perm']==perm]['spktrns'].values\n",
    "    lowgamma_clust3_spktrns = lowgamma_clust3_perms[lowgamma_clust3_perms['perm']==perm]['spktrns'].values\n",
    "    \n",
    "    highgamma_clust0_spktrns = highgamma_clust0_perms[highgamma_clust0_perms['perm']==perm]['spktrns'].values\n",
    "    highgamma_clust1_spktrns = highgamma_clust1_perms[highgamma_clust1_perms['perm']==perm]['spktrns'].values\n",
    "    highgamma_clust2_spktrns = highgamma_clust2_perms[highgamma_clust2_perms['perm']==perm]['spktrns'].values\n",
    "    \n",
    "    \n",
    "    L0T0 = len(set(theta_clust0_spktrns) & set(lowgamma_clust0_spktrns)) / len(set(theta_clust0_spktrns))\n",
    "    L1T0 = len(set(theta_clust0_spktrns) & set(lowgamma_clust1_spktrns)) / len(set(theta_clust0_spktrns))\n",
    "    L2T0 = len(set(theta_clust0_spktrns) & set(lowgamma_clust2_spktrns)) / len(set(theta_clust0_spktrns))\n",
    "    L3T0 = len(set(theta_clust0_spktrns) & set(lowgamma_clust3_spktrns)) / len(set(theta_clust0_spktrns))\n",
    "    \n",
    "    L0T1 = len(set(theta_clust1_spktrns) & set(lowgamma_clust0_spktrns)) / len(set(theta_clust1_spktrns))\n",
    "    L1T1 = len(set(theta_clust1_spktrns) & set(lowgamma_clust1_spktrns)) / len(set(theta_clust1_spktrns))\n",
    "    L2T1 = len(set(theta_clust1_spktrns) & set(lowgamma_clust2_spktrns)) / len(set(theta_clust1_spktrns))\n",
    "    L3T1 = len(set(theta_clust1_spktrns) & set(lowgamma_clust3_spktrns)) / len(set(theta_clust1_spktrns))\n",
    "\n",
    "    L0T2 = len(set(theta_clust2_spktrns) & set(lowgamma_clust0_spktrns)) / len(set(theta_clust2_spktrns))\n",
    "    L1T2 = len(set(theta_clust2_spktrns) & set(lowgamma_clust1_spktrns)) / len(set(theta_clust2_spktrns))\n",
    "    L2T2 = len(set(theta_clust2_spktrns) & set(lowgamma_clust2_spktrns)) / len(set(theta_clust2_spktrns))\n",
    "    L3T2 = len(set(theta_clust2_spktrns) & set(lowgamma_clust3_spktrns)) / len(set(theta_clust2_spktrns))\n",
    "\n",
    "    L0T3 = len(set(theta_clust3_spktrns) & set(lowgamma_clust0_spktrns)) / len(set(theta_clust3_spktrns))\n",
    "    L1T3 = len(set(theta_clust3_spktrns) & set(lowgamma_clust1_spktrns)) / len(set(theta_clust3_spktrns))\n",
    "    L2T3 = len(set(theta_clust3_spktrns) & set(lowgamma_clust2_spktrns)) / len(set(theta_clust3_spktrns))\n",
    "    L3T3 = len(set(theta_clust3_spktrns) & set(lowgamma_clust3_spktrns)) / len(set(theta_clust3_spktrns))\n",
    "    \n",
    "    H0T0 = len(set(theta_clust0_spktrns) & set(highgamma_clust0_spktrns)) / len(set(theta_clust0_spktrns))\n",
    "    H1T0 = len(set(theta_clust0_spktrns) & set(highgamma_clust1_spktrns)) / len(set(theta_clust0_spktrns))\n",
    "    H2T0 = len(set(theta_clust0_spktrns) & set(highgamma_clust2_spktrns)) / len(set(theta_clust0_spktrns))\n",
    "\n",
    "    H0T1 = len(set(theta_clust1_spktrns) & set(highgamma_clust0_spktrns)) / len(set(theta_clust1_spktrns))\n",
    "    H1T1 = len(set(theta_clust1_spktrns) & set(highgamma_clust1_spktrns)) / len(set(theta_clust1_spktrns))\n",
    "    H2T1 = len(set(theta_clust1_spktrns) & set(highgamma_clust2_spktrns)) / len(set(theta_clust1_spktrns))\n",
    "\n",
    "    H0T2 = len(set(theta_clust2_spktrns) & set(highgamma_clust0_spktrns)) / len(set(theta_clust2_spktrns))\n",
    "    H1T2 = len(set(theta_clust2_spktrns) & set(highgamma_clust1_spktrns)) / len(set(theta_clust2_spktrns))\n",
    "    H2T2 = len(set(theta_clust2_spktrns) & set(highgamma_clust2_spktrns)) / len(set(theta_clust2_spktrns))\n",
    "\n",
    "    H0T3 = len(set(theta_clust3_spktrns) & set(highgamma_clust0_spktrns)) / len(set(theta_clust3_spktrns))\n",
    "    H1T3 = len(set(theta_clust3_spktrns) & set(highgamma_clust1_spktrns)) / len(set(theta_clust3_spktrns))\n",
    "    H2T3 = len(set(theta_clust3_spktrns) & set(highgamma_clust2_spktrns)) / len(set(theta_clust3_spktrns))\n",
    "    \n",
    "    perm_cond_probs.append(pd.DataFrame({'perm': [perm],\n",
    "                                         'L0T0': [L0T0],\n",
    "                                         'L1T0': [L1T0],\n",
    "                                         'L2T0': [L2T0],\n",
    "                                         'L3T0': [L3T0],\n",
    "                                         'L0T1': [L0T1],\n",
    "                                         'L1T1': [L1T1],\n",
    "                                         'L2T1': [L2T1],\n",
    "                                         'L3T1': [L3T1],\n",
    "                                         'L0T2': [L0T2],\n",
    "                                         'L1T2': [L1T2],\n",
    "                                         'L2T2': [L2T2],\n",
    "                                         'L3T2': [L3T2],\n",
    "                                         'L0T3': [L0T3],\n",
    "                                         'L1T3': [L1T3],\n",
    "                                         'L2T3': [L2T3],\n",
    "                                         'L3T3': [L3T3],\n",
    "                                         'H0T0': [H0T0],\n",
    "                                         'H1T0': [H1T0],\n",
    "                                         'H2T0': [H2T0],\n",
    "                                         'H0T1': [H0T1],\n",
    "                                         'H1T1': [H1T1],\n",
    "                                         'H2T1': [H2T1],\n",
    "                                         'H0T2': [H0T2],\n",
    "                                         'H1T2': [H1T2],\n",
    "                                         'H2T2': [H2T2],\n",
    "                                         'H0T3': [H0T3],\n",
    "                                         'H1T3': [H1T3],\n",
    "                                         'H2T3': [H2T3]\n",
    "                                        }))\n",
    "    \n",
    "perm_cond_probs = pd.concat(perm_cond_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c701313",
   "metadata": {},
   "source": [
    "They should add up to 1 per theta cluster column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f77074",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(L0T0 + L1T0 + L2T0 + L3T0, L0T1 + L1T1 + L2T1 + L3T1, L0T2 + L1T2 + L2T2 + L3T2, L0T3 + L1T3 + L2T3 + L3T3)\n",
    "print(H0T0 + H1T0 + H2T0, H0T1 + H1T1 + H2T1, H0T2 + H1T2 + H2T2, H0T3 + H1T3 + H2T3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b270827e",
   "metadata": {},
   "source": [
    "You can take a look at each dataset's conditional probability matrices: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a657db",
   "metadata": {},
   "outputs": [],
   "source": [
    "for perm in npermlist: \n",
    "    \n",
    "    subperm = perm_cond_probs[perm_cond_probs['perm']==perm]\n",
    "    \n",
    "    L0T0 = subperm['L0T0'].values[0]\n",
    "    L1T0 = subperm['L1T0'].values[0]\n",
    "    L2T0 = subperm['L2T0'].values[0]\n",
    "    L3T0 = subperm['L3T0'].values[0]\n",
    "    \n",
    "    L0T1 = subperm['L0T0'].values[0]\n",
    "    L1T1 = subperm['L1T0'].values[0]\n",
    "    L2T1 = subperm['L2T0'].values[0]\n",
    "    L3T1 = subperm['L3T0'].values[0]\n",
    "\n",
    "    L0T2 = subperm['L0T2'].values[0]\n",
    "    L1T2 = subperm['L1T2'].values[0]\n",
    "    L2T2 = subperm['L2T2'].values[0]\n",
    "    L3T2 = subperm['L3T2'].values[0]\n",
    "    \n",
    "    L0T3 = subperm['L0T3'].values[0]\n",
    "    L1T3 = subperm['L1T3'].values[0]\n",
    "    L2T3 = subperm['L2T3'].values[0]\n",
    "    L3T3 = subperm['L3T3'].values[0]\n",
    "    \n",
    "    LgivenT = {'Tdesc': [L0T0,L1T0,L2T0,L3T0],\n",
    "               'Tasc': [L0T1,L1T1,L2T1,L3T1],\n",
    "               'Tearlydesc': [L0T2,L1T2,L2T2,L3T2],\n",
    "               'Tuni': [L0T3,L1T3,L2T3,L3T3]\n",
    "              }\n",
    "    LgivenT_df = pd.DataFrame(LgivenT)\n",
    "\n",
    "    T = pd.Series(['Learlydesc','Llatedesc','Lpeak','Luni'])\n",
    "    LgivenT_df = LgivenT_df.set_index(T)\n",
    "    \n",
    "    H0T0 = subperm['H0T0'].values[0]\n",
    "    H1T0 = subperm['H1T0'].values[0]\n",
    "    H2T0 = subperm['H2T0'].values[0]\n",
    "    \n",
    "    H0T1 = subperm['H0T1'].values[0]\n",
    "    H1T1 = subperm['H1T1'].values[0]\n",
    "    H2T1 = subperm['H2T1'].values[0]\n",
    "\n",
    "    H0T2 = subperm['H0T2'].values[0]\n",
    "    H1T2 = subperm['H1T2'].values[0]\n",
    "    H2T2 = subperm['H2T2'].values[0]\n",
    "\n",
    "    H0T3 = subperm['H0T3'].values[0]\n",
    "    H1T3 = subperm['H1T3'].values[0]\n",
    "    H2T3 = subperm['H2T3'].values[0]\n",
    "\n",
    "\n",
    "    HgivenT = {'Tdesc': [H0T0,H1T0,H2T0],\n",
    "               'Tasc': [H0T1,H1T1,H2T1],\n",
    "               'Tearlydesc': [H0T2,H1T2,H2T2],\n",
    "               'Tuni': [H0T3,H1T3,H2T3]\n",
    "              }\n",
    "    HgivenT_df = pd.DataFrame(HgivenT)\n",
    "\n",
    "    T = pd.Series(['Hdesc','Hasc','Huni'])\n",
    "    HgivenT_df = HgivenT_df.set_index(T)\n",
    "    \n",
    "    sns.set(font_scale=2)\n",
    "    fig,ax = plt.subplots(1,2,figsize=(16,6))\n",
    "\n",
    "\n",
    "    g = sns.heatmap(data=LgivenT_df,\n",
    "                    vmin=0,\n",
    "                    vmax=1,\n",
    "                    annot=True,\n",
    "                    annot_kws={\"size\": 16},\n",
    "                    ax=ax[0]\n",
    "                   ).set_title('perm'+str(perm)+'lowgamma clust id given theta clust id')\n",
    "\n",
    "\n",
    "\n",
    "    g = sns.heatmap(data=HgivenT_df,\n",
    "                    vmin=0,\n",
    "                    vmax=1,\n",
    "                    annot=True,\n",
    "                    annot_kws={\"size\": 16},\n",
    "                    ax=ax[1]\n",
    "                   ).set_title('perm'+str(perm)+'highgamma clust id given theta clust id')\n",
    "\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f361b839",
   "metadata": {},
   "source": [
    "### Supplementary Figure 2A (top matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fd3404",
   "metadata": {},
   "outputs": [],
   "source": [
    "for perm in npermlist: \n",
    "    \n",
    "    subperm = perm_cond_probs[perm_cond_probs['perm']==perm]\n",
    "    \n",
    "    L0T0 = subperm['L0T0'].values[0]\n",
    "    L1T0 = subperm['L1T0'].values[0]\n",
    "    L2T0 = subperm['L2T0'].values[0]\n",
    "    L3T0 = subperm['L3T0'].values[0]\n",
    "    \n",
    "    L0T1 = subperm['L0T0'].values[0]\n",
    "    L1T1 = subperm['L1T0'].values[0]\n",
    "    L2T1 = subperm['L2T0'].values[0]\n",
    "    L3T1 = subperm['L3T0'].values[0]\n",
    "\n",
    "    L0T2 = subperm['L0T2'].values[0]\n",
    "    L1T2 = subperm['L1T2'].values[0]\n",
    "    L2T2 = subperm['L2T2'].values[0]\n",
    "    L3T2 = subperm['L3T2'].values[0]\n",
    "    \n",
    "    L0T3 = subperm['L0T3'].values[0]\n",
    "    L1T3 = subperm['L1T3'].values[0]\n",
    "    L2T3 = subperm['L2T3'].values[0]\n",
    "    L3T3 = subperm['L3T3'].values[0]\n",
    "    \n",
    "    LgivenT = {'Tdesc': [L0T0,L1T0,L2T0,L3T0],\n",
    "               'Tasc': [L0T1,L1T1,L2T1,L3T1],\n",
    "               'Tearlydesc': [L0T2,L1T2,L2T2,L3T2],\n",
    "               'Tuni': [L0T3,L1T3,L2T3,L3T3]\n",
    "              }\n",
    "    LgivenT_df = pd.DataFrame(LgivenT)\n",
    "\n",
    "    T = pd.Series(['Learlydesc','Llatedesc','Lpeak','Luni'])\n",
    "    LgivenT_df = LgivenT_df.set_index(T)\n",
    "    \n",
    "    H0T0 = subperm['H0T0'].values[0]\n",
    "    H1T0 = subperm['H1T0'].values[0]\n",
    "    H2T0 = subperm['H2T0'].values[0]\n",
    "    \n",
    "    H0T1 = subperm['H0T1'].values[0]\n",
    "    H1T1 = subperm['H1T1'].values[0]\n",
    "    H2T1 = subperm['H2T1'].values[0]\n",
    "\n",
    "    H0T2 = subperm['H0T2'].values[0]\n",
    "    H1T2 = subperm['H1T2'].values[0]\n",
    "    H2T2 = subperm['H2T2'].values[0]\n",
    "\n",
    "    H0T3 = subperm['H0T3'].values[0]\n",
    "    H1T3 = subperm['H1T3'].values[0]\n",
    "    H2T3 = subperm['H2T3'].values[0]\n",
    "\n",
    "\n",
    "    HgivenT = {'Tdesc': [H0T0,H1T0,H2T0],\n",
    "               'Tasc': [H0T1,H1T1,H2T1],\n",
    "               'Tearlydesc': [H0T2,H1T2,H2T2],\n",
    "               'Tuni': [H0T3,H1T3,H2T3]\n",
    "              }\n",
    "    HgivenT_df = pd.DataFrame(HgivenT)\n",
    "\n",
    "    T = pd.Series(['Hdesc','Hasc','Huni'])\n",
    "    HgivenT_df = HgivenT_df.set_index(T)\n",
    "    \n",
    "    sns.set(font_scale=2)\n",
    "    fig,ax = plt.subplots(1,2,figsize=(16,6))\n",
    "\n",
    "\n",
    "    g = sns.heatmap(data=LgivenT_df,\n",
    "                    vmin=0,\n",
    "                    vmax=1,\n",
    "                    annot=True,\n",
    "                    annot_kws={\"size\": 16},\n",
    "                    ax=ax[0]\n",
    "                   ).set_title('perm'+str(perm)+'lowgamma clust id given theta clust id')\n",
    "\n",
    "\n",
    "\n",
    "    g = sns.heatmap(data=HgivenT_df,\n",
    "                    vmin=0,\n",
    "                    vmax=1,\n",
    "                    annot=True,\n",
    "                    annot_kws={\"size\": 16},\n",
    "                    ax=ax[1]\n",
    "                   ).set_title('perm'+str(perm)+'highgamma clust id given theta clust id')\n",
    "\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90995702",
   "metadata": {},
   "source": [
    "### Supplementary Figure 2A (bottom matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62218946",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='whitegrid',font_scale=1.2)\n",
    "fig,ax = plt.subplots(3,4,figsize=(10,6))\n",
    "\n",
    "ax[0][0].hist(perm_cond_probs['H0T0'].values,alpha=0.4,color='grey')\n",
    "ax[0][0].vlines(x=trueH0T0,ymin=0,ymax=2,color='purple',linewidth = 4)\n",
    "\n",
    "#find all perm values that are greater than or equal to true value\n",
    "geq = [i for i in perm_cond_probs['H0T0'].values if i>=trueH0T0]\n",
    "p_geq_H0T0 =  len(geq) / len(perm_cond_probs['H0T0'].values)\n",
    "ax[0][0].text(0.2,5,str(p_geq_H0T0))\n",
    "\n",
    "ax[0][1].hist(perm_cond_probs['H0T1'].values,alpha=0.4,color='grey')\n",
    "ax[0][1].vlines(x=trueH0T1,ymin=0,ymax=2,color='purple',linewidth = 4)\n",
    "\n",
    "#find all perm values that are greater than or equal to true value\n",
    "geq = [i for i in perm_cond_probs['H0T1'].values if i>=trueH0T1]\n",
    "p_geq_H0T1 =  len(geq) / len(perm_cond_probs['H0T1'].values)\n",
    "ax[0][1].text(0.2,5,str(p_geq_H0T1))\n",
    "\n",
    "ax[0][2].hist(perm_cond_probs['H0T2'].values,alpha=0.4,color='grey')\n",
    "ax[0][2].vlines(x=trueH0T2,ymin=0,ymax=2,color='purple',linewidth = 4)\n",
    "\n",
    "#find all perm values that are greater than or equal to true value\n",
    "geq = [i for i in perm_cond_probs['H0T2'].values if i>=trueH0T2]\n",
    "p_geq_H0T2 =  len(geq) / len(perm_cond_probs['H0T2'].values)\n",
    "ax[0][2].text(0.1,5,str(p_geq_H0T2))\n",
    "\n",
    "ax[0][3].hist(perm_cond_probs['H0T3'].values,alpha=0.4,color='grey')\n",
    "ax[0][3].vlines(x=trueH0T3,ymin=0,ymax=2,color='purple',linewidth = 4)\n",
    "\n",
    "#find all perm values that are greater than or equal to true value\n",
    "geq = [i for i in perm_cond_probs['H0T3'].values if i>=trueH0T3]\n",
    "p_geq_H0T3 =  len(geq) / len(perm_cond_probs['H0T3'].values)\n",
    "ax[0][3].text(0.1,2,str(p_geq_H0T3))\n",
    "\n",
    "ax[1][0].hist(perm_cond_probs['H1T0'].values,alpha=0.4,color='grey')\n",
    "ax[1][0].vlines(x=trueH1T0,ymin=0,ymax=2,color='purple',linewidth = 4)\n",
    "\n",
    "#find all perm values that are greater than or equal to true value\n",
    "geq = [i for i in perm_cond_probs['H1T0'].values if i>=trueH1T0]\n",
    "p_geq_H1T0 =  len(geq) / len(perm_cond_probs['H1T0'].values)\n",
    "ax[1][0].text(0.026,5,str(p_geq_H1T0))\n",
    "\n",
    "ax[1][1].hist(perm_cond_probs['H1T1'].values,alpha=0.4,color='grey')\n",
    "ax[1][1].vlines(x=trueH1T1,ymin=0,ymax=2,color='purple',linewidth = 4)\n",
    "\n",
    "#find all perm values that are greater than or equal to true value\n",
    "geq = [i for i in perm_cond_probs['H1T1'].values if i>=trueH1T1]\n",
    "p_geq_H1T1 =  len(geq) / len(perm_cond_probs['H1T1'].values)\n",
    "ax[1][1].text(0.1,5,str(p_geq_H1T1))\n",
    "\n",
    "ax[1][2].hist(perm_cond_probs['H1T2'].values,alpha=0.4,color='grey')\n",
    "ax[1][2].vlines(x=trueH1T2,ymin=0,ymax=2,color='purple',linewidth = 4)\n",
    "\n",
    "#find all perm values that are greater than or equal to true value\n",
    "geq = [i for i in perm_cond_probs['H1T2'].values if i>=trueH1T2]\n",
    "p_geq_H1T2 =  len(geq) / len(perm_cond_probs['H1T2'].values)\n",
    "ax[1][2].text(0.2,5,str(p_geq_H1T2))\n",
    "\n",
    "ax[1][3].hist(perm_cond_probs['H1T3'].values,alpha=0.4,color='grey')\n",
    "ax[1][3].vlines(x=trueH1T3,ymin=0,ymax=2,color='purple',linewidth = 4)\n",
    "\n",
    "#find all perm values that are greater than or equal to true value\n",
    "geq = [i for i in perm_cond_probs['H1T3'].values if i>=trueH1T3]\n",
    "p_geq_H1T3 =  len(geq) / len(perm_cond_probs['H1T3'].values)\n",
    "ax[1][3].text(0.05,5,str(p_geq_H1T3))\n",
    "\n",
    "ax[2][0].hist(perm_cond_probs['H2T0'].values,alpha=0.4,color='grey')\n",
    "ax[2][0].vlines(x=trueH2T0,ymin=0,ymax=2,color='purple',linewidth = 4)\n",
    "\n",
    "#find all perm values that are greater than or equal to true value\n",
    "geq = [i for i in perm_cond_probs['H2T0'].values if i>=trueH2T0]\n",
    "p_geq_H2T0 =  len(geq) / len(perm_cond_probs['H2T0'].values)\n",
    "ax[2][0].text(0.5,5,str(p_geq_H2T0))\n",
    "\n",
    "ax[2][1].hist(perm_cond_probs['H2T1'].values,alpha=0.4,color='grey')\n",
    "ax[2][1].vlines(x=trueH2T1,ymin=0,ymax=2,color='purple',linewidth = 4)\n",
    "\n",
    "#find all perm values that are greater than or equal to true value\n",
    "geq = [i for i in perm_cond_probs['H2T1'].values if i>=trueH2T1]\n",
    "p_geq_H2T1 =  len(geq) / len(perm_cond_probs['H2T1'].values)\n",
    "ax[2][1].text(0.6,5,str(p_geq_H2T1))\n",
    "\n",
    "ax[2][2].hist(perm_cond_probs['H2T2'].values,alpha=0.4,color='grey')\n",
    "ax[2][2].vlines(x=trueH2T2,ymin=0,ymax=2,color='purple',linewidth = 4)\n",
    "\n",
    "#find all perm values that are greater than or equal to true value\n",
    "geq = [i for i in perm_cond_probs['H2T2'].values if i>=trueH2T2]\n",
    "p_geq_H2T2 =  len(geq) / len(perm_cond_probs['H2T2'].values)\n",
    "ax[2][2].text(0.8,5,str(p_geq_H2T2))\n",
    "\n",
    "ax[2][3].hist(perm_cond_probs['H2T3'].values,alpha=0.4,color='grey')\n",
    "ax[2][3].vlines(x=trueH2T3,ymin=0,ymax=2,color='purple',linewidth = 4)\n",
    "\n",
    "#find all perm values that are greater than or equal to true value\n",
    "geq = [i for i in perm_cond_probs['H2T3'].values if i>=trueH2T3]\n",
    "p_geq_H2T3 =  len(geq) / len(perm_cond_probs['H2T3'].values)\n",
    "ax[2][3].text(0.8,3,str(p_geq_H2T3))\n",
    "\n",
    "\n",
    "\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab49415",
   "metadata": {},
   "source": [
    "#### rinse and repeat for the joint probabilities,\n",
    "You'll use the same permuted datasets here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed84b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_joint_probs = []\n",
    "for perm in npermlist: \n",
    "    \n",
    "    theta_clust0_spktrns = theta_clust0_perms[theta_clust0_perms['perm']==perm]['spktrns'].values\n",
    "    theta_clust1_spktrns = theta_clust1_perms[theta_clust1_perms['perm']==perm]['spktrns'].values\n",
    "    theta_clust2_spktrns = theta_clust2_perms[theta_clust2_perms['perm']==perm]['spktrns'].values\n",
    "    theta_clust3_spktrns = theta_clust3_perms[theta_clust3_perms['perm']==perm]['spktrns'].values\n",
    "    \n",
    "    lowgamma_clust0_spktrns = lowgamma_clust0_perms[lowgamma_clust0_perms['perm']==perm]['spktrns'].values\n",
    "    lowgamma_clust1_spktrns = lowgamma_clust1_perms[lowgamma_clust1_perms['perm']==perm]['spktrns'].values\n",
    "    lowgamma_clust2_spktrns = lowgamma_clust2_perms[lowgamma_clust2_perms['perm']==perm]['spktrns'].values\n",
    "    lowgamma_clust3_spktrns = lowgamma_clust3_perms[lowgamma_clust3_perms['perm']==perm]['spktrns'].values\n",
    "    \n",
    "    highgamma_clust0_spktrns = highgamma_clust0_perms[highgamma_clust0_perms['perm']==perm]['spktrns'].values\n",
    "    highgamma_clust1_spktrns = highgamma_clust1_perms[highgamma_clust1_perms['perm']==perm]['spktrns'].values\n",
    "    highgamma_clust2_spktrns = highgamma_clust2_perms[highgamma_clust2_perms['perm']==perm]['spktrns'].values\n",
    "    \n",
    "    \n",
    "    H0L0 = len(set(highgamma_clust0_spktrns) & set(lowgamma_clust0_spktrns)) / ((len(highgamma_clust0_spktrns) + len(lowgamma_clust0_spktrns)) - len(set(highgamma_clust0_spktrns) & set(lowgamma_clust0_spktrns)))\n",
    "    H0L1 = len(set(highgamma_clust0_spktrns) & set(lowgamma_clust1_spktrns)) / ((len(highgamma_clust0_spktrns) + len(lowgamma_clust1_spktrns)) - len(set(highgamma_clust0_spktrns) & set(lowgamma_clust1_spktrns)))\n",
    "    H0L2 = len(set(highgamma_clust0_spktrns) & set(lowgamma_clust2_spktrns)) / ((len(highgamma_clust0_spktrns) + len(lowgamma_clust2_spktrns)) - len(set(highgamma_clust0_spktrns) & set(lowgamma_clust2_spktrns)))\n",
    "    H0L3 = len(set(highgamma_clust0_spktrns) & set(lowgamma_clust3_spktrns)) / ((len(highgamma_clust0_spktrns) + len(lowgamma_clust3_spktrns)) - len(set(highgamma_clust0_spktrns) & set(lowgamma_clust3_spktrns)))\n",
    "\n",
    "    H1L0 = len(set(highgamma_clust1_spktrns) & set(lowgamma_clust0_spktrns)) / ((len(highgamma_clust1_spktrns) + len(lowgamma_clust0_spktrns)) - len(set(highgamma_clust1_spktrns) & set(lowgamma_clust0_spktrns)))\n",
    "    H1L1 = len(set(highgamma_clust1_spktrns) & set(lowgamma_clust1_spktrns)) / ((len(highgamma_clust1_spktrns) + len(lowgamma_clust1_spktrns)) - len(set(highgamma_clust1_spktrns) & set(lowgamma_clust1_spktrns)))\n",
    "    H1L2 = len(set(highgamma_clust1_spktrns) & set(lowgamma_clust2_spktrns)) / ((len(highgamma_clust1_spktrns) + len(lowgamma_clust2_spktrns)) - len(set(highgamma_clust1_spktrns) & set(lowgamma_clust2_spktrns)))\n",
    "    H1L3 = len(set(highgamma_clust1_spktrns) & set(lowgamma_clust3_spktrns)) / ((len(highgamma_clust1_spktrns) + len(lowgamma_clust3_spktrns)) - len(set(highgamma_clust1_spktrns) & set(lowgamma_clust3_spktrns)))\n",
    "\n",
    "    H2L0 = len(set(highgamma_clust2_spktrns) & set(lowgamma_clust0_spktrns)) / ((len(highgamma_clust2_spktrns) + len(lowgamma_clust0_spktrns)) - len(set(highgamma_clust2_spktrns) & set(lowgamma_clust0_spktrns)))\n",
    "    H2L1 = len(set(highgamma_clust2_spktrns) & set(lowgamma_clust1_spktrns)) / ((len(highgamma_clust2_spktrns) + len(lowgamma_clust1_spktrns)) - len(set(highgamma_clust2_spktrns) & set(lowgamma_clust1_spktrns)))\n",
    "    H2L2 = len(set(highgamma_clust2_spktrns) & set(lowgamma_clust2_spktrns)) / ((len(highgamma_clust2_spktrns) + len(lowgamma_clust2_spktrns)) - len(set(highgamma_clust2_spktrns) & set(lowgamma_clust2_spktrns)))\n",
    "    H2L3 = len(set(highgamma_clust2_spktrns) & set(lowgamma_clust3_spktrns)) / ((len(highgamma_clust2_spktrns) + len(lowgamma_clust3_spktrns)) - len(set(highgamma_clust2_spktrns) & set(lowgamma_clust3_spktrns)))\n",
    "\n",
    "\n",
    "    perm_joint_probs.append(pd.DataFrame({'perm': [perm],\n",
    "                                         'H0L0': [H0L0],\n",
    "                                         'H0L1': [H0L1],\n",
    "                                         'H0L2': [H0L2],\n",
    "                                         'H0L3': [H0L3],\n",
    "                                         'H1L0': [H1L0],\n",
    "                                         'H1L1': [H1L1],\n",
    "                                         'H1L2': [H1L2],\n",
    "                                         'H1L3': [H1L3],\n",
    "                                         'H2L0': [H2L0],\n",
    "                                         'H2L1': [H2L1],\n",
    "                                         'H2L2': [H2L2],\n",
    "                                         'H2L3': [H2L3]\n",
    "                                        }))\n",
    "    \n",
    "perm_joint_probs = pd.concat(perm_joint_probs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06b149e",
   "metadata": {},
   "source": [
    "You can take a look at what the shuffled data joint probability heatmaps would look like: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f64ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for perm in npermlist: \n",
    "    \n",
    "    subperm = perm_joint_probs[perm_joint_probs['perm']==perm]\n",
    "    \n",
    "    H0L0 = subperm['H0L0'].values[0]\n",
    "    H0L1 = subperm['H0L1'].values[0]\n",
    "    H0L2 = subperm['H0L2'].values[0]\n",
    "    H0L3 = subperm['H0L3'].values[0]\n",
    "    \n",
    "    H1L0 = subperm['H1L0'].values[0]\n",
    "    H1L1 = subperm['H1L1'].values[0]\n",
    "    H1L2 = subperm['H1L2'].values[0]\n",
    "    H1L3 = subperm['H1L3'].values[0]\n",
    "\n",
    "    H2L0 = subperm['H2L0'].values[0]\n",
    "    H2L1 = subperm['H2L1'].values[0]\n",
    "    H2L2 = subperm['H2L2'].values[0]\n",
    "    H2L3 = subperm['H2L3'].values[0]\n",
    "    \n",
    "    \n",
    "    HandL = {'H0': [H0L0,H0L1,H0L2,H0L3],\n",
    "             'H1': [H1L0,H1L1,H1L2,H1L3],\n",
    "             'H2': [H2L0,H2L1,H2L2,H2L3]\n",
    "              }\n",
    "    HandL_df = pd.DataFrame(HandL)\n",
    "\n",
    "    L = pd.Series(['Learlydesc','Learlyasc','Lpeak','Luni'])\n",
    "    HandL_df = HandL_df.set_index(L)\n",
    "    \n",
    "    \n",
    "    sns.set(font_scale=2)\n",
    "    fig,ax = plt.subplots(figsize=(8,4))\n",
    "    g = sns.heatmap(data=HandL_df,\n",
    "                        vmin=0,\n",
    "                        vmax=1,\n",
    "                        annot=True,\n",
    "                        annot_kws={\"size\": 16},\n",
    "                        ax=ax\n",
    "                       ).set_title('perm'+str(perm)+'joint probs \\n lowgamma clust id and highgamma clust id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a2b3f5",
   "metadata": {},
   "source": [
    "### Supplementary Figure 2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6ec9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='whitegrid',font_scale=1.2)\n",
    "fig,ax = plt.subplots(4,3,figsize=(10,8))\n",
    "\n",
    "ax[0][0].hist(perm_joint_probs['H0L0'].values,alpha=0.4,color='grey')\n",
    "ax[0][0].vlines(x=trueH0L0,ymin=0,ymax=2,color='olive',linewidth = 4)\n",
    "\n",
    "#find all perm values that are greater than or equal to true value\n",
    "geq = [i for i in perm_joint_probs['H0L0'].values if i>=trueH0L0]\n",
    "p_geq_H0L0 =  len(geq) / len(perm_joint_probs['H0L0'].values)\n",
    "ax[0][0].text(0.025,5,str(p_geq_H0L0))\n",
    "\n",
    "ax[1][0].hist(perm_joint_probs['H0L1'].values,alpha=0.4,color='grey')\n",
    "ax[1][0].vlines(x=trueH0L1,ymin=0,ymax=2,color='olive',linewidth = 4)\n",
    "\n",
    "#find all perm values that are greater than or equal to true value\n",
    "geq = [i for i in perm_joint_probs['H0L1'].values if i>=trueH0L1]\n",
    "p_geq_H0L1 =  len(geq) / len(perm_joint_probs['H0L1'].values)\n",
    "ax[1][0].text(0.1,5,str(p_geq_H0L1))\n",
    "\n",
    "ax[2][0].hist(perm_joint_probs['H0L2'].values,alpha=0.4,color='grey')\n",
    "ax[2][0].vlines(x=trueH0L2,ymin=0,ymax=2,color='olive',linewidth = 4)\n",
    "\n",
    "#find all perm values that are greater than or equal to true value\n",
    "geq = [i for i in perm_joint_probs['H0L2'].values if i>=trueH0L2]\n",
    "p_geq_H0L2 =  len(geq) / len(perm_joint_probs['H0L2'].values)\n",
    "ax[2][0].text(0.1,5,str(p_geq_H0L2))\n",
    "\n",
    "ax[3][0].hist(perm_joint_probs['H0L3'].values,alpha=0.4,color='grey')\n",
    "ax[3][0].vlines(x=trueH0L3,ymin=0,ymax=2,color='olive',linewidth = 4)\n",
    "\n",
    "#find all perm values that are greater than or equal to true value\n",
    "geq = [i for i in perm_joint_probs['H0L3'].values if i>=trueH0L3]\n",
    "p_geq_H0L3 =  len(geq) / len(perm_joint_probs['H0L3'].values)\n",
    "ax[3][0].text(0.1,5,str(p_geq_H0L3))\n",
    "\n",
    "\n",
    "ax[0][1].hist(perm_joint_probs['H1L0'].values,alpha=0.4,color='grey')\n",
    "ax[0][1].vlines(x=trueH1L0,ymin=0,ymax=2,color='olive',linewidth = 4)\n",
    "\n",
    "#find all perm values that are greater than or equal to true value\n",
    "geq = [i for i in perm_joint_probs['H1L0'].values if i>=trueH1L0]\n",
    "p_geq_H1L0 =  len(geq) / len(perm_joint_probs['H1L0'].values)\n",
    "ax[0][1].text(0.05,5,str(p_geq_H1L0))\n",
    "\n",
    "ax[1][1].hist(perm_joint_probs['H1L1'].values,alpha=0.4,color='grey')\n",
    "ax[1][1].vlines(x=trueH1L1,ymin=0,ymax=2,color='olive',linewidth = 4)\n",
    "\n",
    "#find all perm values that are greater than or equal to true value\n",
    "geq = [i for i in perm_joint_probs['H1L1'].values if i>=trueH1L1]\n",
    "p_geq_H1L1 =  len(geq) / len(perm_joint_probs['H1L1'].values)\n",
    "ax[1][1].text(0.01,5,str(p_geq_H1L1))\n",
    "\n",
    "ax[2][1].hist(perm_joint_probs['H1L2'].values,alpha=0.4,color='grey')\n",
    "ax[2][1].vlines(x=trueH1L2,ymin=0,ymax=2,color='olive',linewidth = 4)\n",
    "\n",
    "#find all perm values that are greater than or equal to true value\n",
    "geq = [i for i in perm_joint_probs['H1L2'].values if i>=trueH1L2]\n",
    "p_geq_H1L2 =  len(geq) / len(perm_joint_probs['H1L2'].values)\n",
    "ax[2][1].text(0.01,5,str(p_geq_H1L2))\n",
    "\n",
    "ax[3][1].hist(perm_joint_probs['H1L3'].values,alpha=0.4,color='grey')\n",
    "ax[3][1].vlines(x=trueH1L3,ymin=0,ymax=2,color='olive',linewidth = 4)\n",
    "\n",
    "#find all perm values that are greater than or equal to true value\n",
    "geq = [i for i in perm_joint_probs['H1L3'].values if i>=trueH1L3]\n",
    "p_geq_H1L3 =  len(geq) / len(perm_joint_probs['H1L3'].values)\n",
    "ax[3][1].text(0.01,4,str(p_geq_H1L3))\n",
    "\n",
    "ax[0][2].hist(perm_joint_probs['H2L0'].values,alpha=0.4,color='grey')\n",
    "ax[0][2].vlines(x=trueH2L0,ymin=0,ymax=2,color='olive',linewidth = 4)\n",
    "\n",
    "#find all perm values that are greater than or equal to true value\n",
    "geq = [i for i in perm_joint_probs['H2L0'].values if i>=trueH2L0]\n",
    "p_geq_H2L0 =  len(geq) / len(perm_joint_probs['H2L0'].values)\n",
    "ax[0][2].text(0.025,3,str(p_geq_H2L0))\n",
    "\n",
    "ax[1][2].hist(perm_joint_probs['H2L1'].values,alpha=0.4,color='grey')\n",
    "ax[1][2].vlines(x=trueH2L1,ymin=0,ymax=2,color='olive',linewidth = 4)\n",
    "\n",
    "#find all perm values that are greater than or equal to true value\n",
    "geq = [i for i in perm_joint_probs['H2L1'].values if i>=trueH2L1]\n",
    "p_geq_H2L1 =  len(geq) / len(perm_joint_probs['H2L1'].values)\n",
    "ax[1][2].text(0.02,3,str(p_geq_H2L1))\n",
    "\n",
    "ax[2][2].hist(perm_joint_probs['H2L2'].values,alpha=0.4,color='grey')\n",
    "ax[2][2].vlines(x=trueH2L2,ymin=0,ymax=2,color='olive',linewidth = 4)\n",
    "\n",
    "#find all perm values that are greater than or equal to true value\n",
    "geq = [i for i in perm_joint_probs['H2L2'].values if i>=trueH2L2]\n",
    "p_geq_H2L2 =  len(geq) / len(perm_joint_probs['H2L2'].values)\n",
    "ax[2][2].text(0.02,1,str(p_geq_H2L2))\n",
    "\n",
    "ax[3][2].hist(perm_joint_probs['H2L3'].values,alpha=0.4,color='grey')\n",
    "ax[3][2].vlines(x=trueH2L3,ymin=0,ymax=2,color='olive',linewidth = 4)\n",
    "\n",
    "#find all perm values that are greater than or equal to true value\n",
    "geq = [i for i in perm_joint_probs['H2L3'].values if i>=trueH2L3]\n",
    "p_geq_H2L3 =  len(geq) / len(perm_joint_probs['H2L3'].values)\n",
    "ax[3][2].text(0.6,3,str(p_geq_H2L3))\n",
    "\n",
    "\n",
    "\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c9fc5a",
   "metadata": {},
   "source": [
    "### example cells below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9d7690",
   "metadata": {},
   "source": [
    "### Figure 4B (top left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d12899e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_id = 'LH02_D14_TETSPK13b'\n",
    "ymax = 0.0175\n",
    "\n",
    "fig = example_cells_by_odor(cell_id,kde_odor,cluster_id_df,ymax,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6800e040",
   "metadata": {},
   "source": [
    "### Figure 4B (bottom left)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ff0bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_id = 'LH16_D29_TETSPK09a'\n",
    "ymax = 0.05\n",
    "\n",
    "fig = example_cells_by_odor(cell_id,kde_odor,cluster_id_df,ymax,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17e3f0e",
   "metadata": {},
   "source": [
    "### Figure 4D (left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac1d6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_id = 'LH16_D25_TETSPK33m'\n",
    "ymax = 0.008\n",
    "fig = example_cells_by_odor(cell_id,kde_odor,cluster_id_df,ymax,0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaded52",
   "metadata": {},
   "source": [
    "### Figure 4E (left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357e1797",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_id = 'LH08_D32_TETSPK09c'\n",
    "ymax = 0.06\n",
    "fig = example_cells_by_odor(cell_id,kde_odor,cluster_id_df,ymax,0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14ed019",
   "metadata": {},
   "source": [
    "For fun, you can take a look at the cells that didn't get theta cluster reassignments below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd32c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ymax= 0.07\n",
    "for cell_id in sorted(stable_cells): \n",
    "    \n",
    "    example_cells_by_side_of_maze(cell_id,kde_odor,cluster_id_df,datapath,ymax,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd371dc",
   "metadata": {},
   "source": [
    "And you can see the ones that did get theta cluster reassignments (in some cases, you might need to change the y scale to see the differences for the lower firing interneurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f88edf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ymax= 0.06\n",
    "for cell_id in sorted(theta_shifting_cells): \n",
    "    \n",
    "    example_cells_by_side_of_maze(cell_id,kde_odor,cluster_id_df,datapath,ymax,0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
